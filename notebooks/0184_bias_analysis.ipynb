{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecaf693-a92a-4419-a291-508ae970cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ­ BIAS ANALYSIS & ADVANCED VISUALIZATIONS\n",
      "Member: ITBIN-2211-0184\n",
      "Time: 2:00 PM - 4:00 PM\n",
      "============================================================\n",
      "âš ï¸ Dataset not found. Downloading from https://raw.githubusercontent.com/msantinelli/fake-news-detection/main/data/raw/liar_dataset.zip...\n",
      "âŒ Error downloading dataset: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/msantinelli/fake-news-detection/main/data/raw/liar_dataset.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not load dataset files",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 122\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/processed/liar_dataset_processed.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded processed dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/liar_dataset_processed.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 125\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded processed dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     df = \u001b[43mload_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomprehensive_political_bias_analysis\u001b[39m(df):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform comprehensive political bias analysis\"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mload_raw_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(os.path.exists(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m required_files):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m download_dataset():\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not load dataset files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Load train, test and validation datasets\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Could not load dataset files"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('data/raw/liar_dataset', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('results/plots', exist_ok=True)\n",
    "os.makedirs('results/reports', exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ­ BIAS ANALYSIS & ADVANCED VISUALIZATIONS\")\n",
    "print(\"Member: ITBIN-2211-0184\")\n",
    "print(\"Time: 2:00 PM - 4:00 PM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Download and extract the dataset if missing\n",
    "def download_dataset():\n",
    "    dataset_url = \"https://raw.githubusercontent.com/msantinelli/fake-news-detection/main/data/raw/liar_dataset.zip\"\n",
    "    print(f\"âš ï¸ Dataset not found. Downloading from {dataset_url}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(dataset_url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        \n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "            # Extract directly to data/raw directory\n",
    "            zip_ref.extractall('data/raw')\n",
    "            print(\"âœ… Dataset downloaded and extracted successfully\")\n",
    "            \n",
    "            # Move files to liar_dataset directory\n",
    "            for file in ['train.tsv', 'test.tsv', 'valid.tsv']:\n",
    "                src = f'data/raw/{file}'\n",
    "                dst = f'data/raw/liar_dataset/{file}'\n",
    "                if os.path.exists(src):\n",
    "                    shutil.move(src, dst)\n",
    "            \n",
    "            print(\"ğŸ“ Files moved to data/raw/liar_dataset/\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error downloading dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "# Load the dataset from raw files\n",
    "def load_raw_dataset():\n",
    "    # Define column names for LIAR dataset\n",
    "    columns = [\n",
    "        'id', 'label', 'statement', 'subject', 'speaker', 'speaker_job', \n",
    "        'state_info', 'party_affiliation', \n",
    "        'barely_true_counts', 'false_counts', 'half_true_counts', \n",
    "        'mostly_true_counts', 'pants_on_fire_counts'\n",
    "    ]\n",
    "    \n",
    "    # Check if files exist, download if missing\n",
    "    required_files = [\n",
    "        'data/raw/liar_dataset/train.tsv',\n",
    "        'data/raw/liar_dataset/test.tsv',\n",
    "        'data/raw/liar_dataset/valid.tsv'\n",
    "    ]\n",
    "    \n",
    "    if not all(os.path.exists(f) for f in required_files):\n",
    "        if not download_dataset():\n",
    "            raise FileNotFoundError(\"Could not load dataset files\")\n",
    "    \n",
    "    # Load train, test and validation datasets\n",
    "    try:\n",
    "        train_df = pd.read_csv('data/raw/liar_dataset/train.tsv', sep='\\t', header=None, names=columns)\n",
    "        test_df = pd.read_csv('data/raw/liar_dataset/test.tsv', sep='\\t', header=None, names=columns)\n",
    "        valid_df = pd.read_csv('data/raw/liar_dataset/valid.tsv', sep='\\t', header=None, names=columns)\n",
    "        \n",
    "        # Add split information\n",
    "        train_df['split'] = 'train'\n",
    "        test_df['split'] = 'test'\n",
    "        valid_df['split'] = 'valid'\n",
    "        \n",
    "        # Combine datasets\n",
    "        df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        print(f\"âœ… Loaded raw dataset: {df.shape}\")\n",
    "        \n",
    "        # Minimal preprocessing\n",
    "        df['text_length'] = df['statement'].apply(len)\n",
    "        df['party_affiliation'] = df['party_affiliation'].fillna('unknown').str.lower().str.strip()\n",
    "        df['subject'] = df['subject'].fillna('unknown').str.lower().str.strip()\n",
    "        df['speaker_job'] = df['speaker_job'].fillna('unknown')\n",
    "        \n",
    "        # Create simplified labels\n",
    "        label_mapping = {\n",
    "            'true': 'true',\n",
    "            'mostly-true': 'mostly-true',\n",
    "            'half-true': 'half-true',\n",
    "            'barely-true': 'barely-true',\n",
    "            'false': 'false',\n",
    "            'pants-fire': 'pants-fire'\n",
    "        }\n",
    "        df['label'] = df['label'].map(label_mapping).fillna('unknown')\n",
    "        \n",
    "        # Save processed data for future use\n",
    "        df.to_csv('data/processed/liar_dataset_processed.csv', index=False)\n",
    "        print(\"ğŸ’¾ Saved processed data to 'data/processed/liar_dataset_processed.csv'\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading raw data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Try to load processed data\n",
    "try:\n",
    "    df = pd.read_csv('data/processed/liar_dataset_processed.csv')\n",
    "    print(f\"âœ… Loaded processed dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    df = load_raw_dataset()\n",
    "\n",
    "def comprehensive_political_bias_analysis(df):\n",
    "    \"\"\"Perform comprehensive political bias analysis\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ›ï¸ COMPREHENSIVE POLITICAL BIAS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    bias_analysis = {}\n",
    "    \n",
    "    # 1. Truth rate by party affiliation\n",
    "    print(\"1ï¸âƒ£ Truth Rate Analysis by Party Affiliation\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Define truth categories\n",
    "    high_truth = ['true', 'mostly-true']\n",
    "    low_truth = ['false', 'pants-fire']\n",
    "    \n",
    "    # Calculate truth rates by party\n",
    "    party_stats = []\n",
    "    top_parties = df['party_affiliation'].value_counts().head(10).index\n",
    "    \n",
    "    for party in top_parties:\n",
    "        party_data = df[df['party_affiliation'] == party]\n",
    "        total_statements = len(party_data)\n",
    "        \n",
    "        high_truth_count = party_data['label'].isin(high_truth).sum()\n",
    "        low_truth_count = party_data['label'].isin(low_truth).sum()\n",
    "        \n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        low_truth_rate = (low_truth_count / total_statements) * 100\n",
    "        \n",
    "        party_stats.append({\n",
    "            'party': party,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "            'low_truth_rate': low_truth_rate,\n",
    "            'high_truth_count': high_truth_count,\n",
    "            'low_truth_count': low_truth_count\n",
    "        })\n",
    "        \n",
    "        print(f\"{party:20} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}% | False: {low_truth_rate:5.1f}%\")\n",
    "    \n",
    "    party_df = pd.DataFrame(party_stats)\n",
    "    bias_analysis['party_truth_rates'] = party_df\n",
    "    \n",
    "    # 2. Subject matter bias analysis\n",
    "    print(f\"\\n2ï¸âƒ£ Subject Matter Bias Analysis\")\n",
    "    print(\"-\" * 32)\n",
    "    \n",
    "    subject_stats = []\n",
    "    top_subjects = df['subject'].value_counts().head(10).index\n",
    "    \n",
    "    for subject in top_subjects:\n",
    "        subject_data = df[df['subject'] == subject]\n",
    "        total_statements = len(subject_data)\n",
    "        \n",
    "        high_truth_count = subject_data['label'].isin(high_truth).sum()\n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        \n",
    "        subject_stats.append({\n",
    "            'subject': subject,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "        })\n",
    "        \n",
    "        print(f\"{subject:25} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    subject_df = pd.DataFrame(subject_stats)\n",
    "    bias_analysis['subject_truth_rates'] = subject_df\n",
    "    \n",
    "    # 3. Speaker role bias analysis\n",
    "    print(f\"\\n3ï¸âƒ£ Speaker Role Bias Analysis\")\n",
    "    print(\"-\" * 28)\n",
    "    \n",
    "    # Clean and analyze speaker jobs\n",
    "    df['speaker_job_clean'] = df['speaker_job'].fillna('Unknown').str.title()\n",
    "    \n",
    "    role_stats = []\n",
    "    top_roles = df['speaker_job_clean'].value_counts().head(10).index\n",
    "    \n",
    "    for role in top_roles:\n",
    "        role_data = df[df['speaker_job_clean'] == role]\n",
    "        total_statements = len(role_data)\n",
    "        \n",
    "        if total_statements >= 10:  # Only analyze roles with sufficient data\n",
    "            high_truth_count = role_data['label'].isin(high_truth).sum()\n",
    "            high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "            \n",
    "            role_stats.append({\n",
    "                'role': role,\n",
    "                'total_statements': total_statements,\n",
    "                'high_truth_rate': high_truth_rate,\n",
    "            })\n",
    "            \n",
    "            print(f\"{role:25} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    role_df = pd.DataFrame(role_stats)\n",
    "    bias_analysis['role_truth_rates'] = role_df\n",
    "    \n",
    "    # 4. Temporal bias analysis (by data split as proxy)\n",
    "    print(f\"\\n4ï¸âƒ£ Data Split Analysis\")\n",
    "    print(\"-\" * 22)\n",
    "    \n",
    "    split_stats = []\n",
    "    for split in df['split'].unique():\n",
    "        split_data = df[df['split'] == split]\n",
    "        total_statements = len(split_data)\n",
    "        \n",
    "        high_truth_count = split_data['label'].isin(high_truth).sum()\n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        \n",
    "        split_stats.append({\n",
    "            'split': split,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "        })\n",
    "        \n",
    "        print(f\"{split:10} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    bias_analysis['split_analysis'] = pd.DataFrame(split_stats)\n",
    "    \n",
    "    return bias_analysis\n",
    "\n",
    "def create_political_bias_visualizations(df, bias_analysis):\n",
    "    \"\"\"Create comprehensive political bias visualizations\"\"\"\n",
    "    print(\"\\nğŸ“Š Creating political bias visualizations...\")\n",
    "    \n",
    "    # Create large figure with multiple subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(22, 18))\n",
    "    fig.suptitle('Comprehensive Political Bias Analysis', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # 1. Party truth rates (horizontal bar chart)\n",
    "    party_df = bias_analysis['party_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "    colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(party_df)))\n",
    "    \n",
    "    bars = axes[0,0].barh(range(len(party_df)), party_df['high_truth_rate'], color=colors)\n",
    "    axes[0,0].set_yticks(range(len(party_df)))\n",
    "    axes[0,0].set_yticklabels(party_df['party'], fontsize=10)\n",
    "    axes[0,0].set_title('Truth Rate by Party Affiliation', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('High Truth Rate (%)')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, rate) in enumerate(zip(bars, party_df['high_truth_rate'])):\n",
    "        axes[0,0].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{rate:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    # 2. Subject matter truth rates\n",
    "    subject_df = bias_analysis['subject_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "    colors = plt.cm.Greens(np.linspace(0.3, 0.9, len(subject_df)))\n",
    "    \n",
    "    bars = axes[0,1].barh(range(len(subject_df)), subject_df['high_truth_rate'], color=colors)\n",
    "    axes[0,1].set_yticks(range(len(subject_df)))\n",
    "    axes[0,1].set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in subject_df['subject']], fontsize=9)\n",
    "    axes[0,1].set_title('Truth Rate by Subject Matter', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('High Truth Rate (%)')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, rate) in enumerate(zip(bars, subject_df['high_truth_rate'])):\n",
    "        axes[0,1].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{rate:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    # 3. Speaker role analysis\n",
    "    if len(bias_analysis['role_truth_rates']) > 0:\n",
    "        role_df = bias_analysis['role_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "        colors = plt.cm.Oranges(np.linspace(0.3, 0.9, len(role_df)))\n",
    "        \n",
    "        bars = axes[0,2].barh(range(len(role_df)), role_df['high_truth_rate'], color=colors)\n",
    "        axes[0,2].set_yticks(range(len(role_df)))\n",
    "        axes[0,2].set_yticklabels([r[:15] + '...' if len(r) > 15 else r for r in role_df['role']], fontsize=9)\n",
    "        axes[0,2].set_title('Truth Rate by Speaker Role', fontweight='bold')\n",
    "        axes[0,2].set_xlabel('High Truth Rate (%)')\n",
    "    else:\n",
    "        axes[0,2].axis('off')\n",
    "    \n",
    "    # 4. Party vs Subject heatmap (truth rates)\n",
    "    party_subject_pivot = df.groupby(['party_affiliation', 'subject']).apply(\n",
    "        lambda x: (x['label'].isin(['true', 'mostly-true']).sum() / len(x)) * 100\n",
    "    ).reset_index(name='truth_rate')\n",
    "    \n",
    "    # Filter for top parties and subjects\n",
    "    top_parties = df['party_affiliation'].value_counts().head(6).index\n",
    "    top_subjects = df['subject'].value_counts().head(6).index\n",
    "    \n",
    "    pivot_filtered = party_subject_pivot[\n",
    "        (party_subject_pivot['party_affiliation'].isin(top_parties)) &\n",
    "        (party_subject_pivot['subject'].isin(top_subjects))\n",
    "    ]\n",
    "    \n",
    "    if not pivot_filtered.empty:\n",
    "        pivot_table = pivot_filtered.pivot(index='party_affiliation', columns='subject', values='truth_rate')\n",
    "        sns.heatmap(pivot_table, annot=True, cmap='RdYlGn', center=50, ax=axes[1,0], fmt='.1f')\n",
    "        axes[1,0].set_title('Truth Rate Heatmap: Party vs Subject', fontweight='bold')\n",
    "        axes[1,0].set_ylabel('Party Affiliation')\n",
    "        axes[1,0].set_xlabel('Subject')\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'Insufficient data for heatmap', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,0].set_title('Truth Rate Heatmap: Party vs Subject', fontweight='bold')\n",
    "    \n",
    "    # 5. Statement distribution by party\n",
    "    party_counts = df['party_affiliation'].value_counts().head(8)\n",
    "    axes[1,2].pie(party_counts.values, labels=[p[:10] + '...' if len(p) > 10 else p for p in party_counts.index],\n",
    "                  autopct='%1.1f%%', startangle=90)\n",
    "    axes[1,2].set_title('Statement Distribution by Party', fontweight='bold')\n",
    "    \n",
    "    # 6. Truth rate distribution across all parties\n",
    "    all_party_truth_rates = []\n",
    "    for party in df['party_affiliation'].unique():\n",
    "        party_data = df[df['party_affiliation'] == party]\n",
    "        if len(party_data) >= 5:  # Minimum statements for reliable rate\n",
    "            truth_rate = (party_data['label'].isin(['true', 'mostly-true']).sum() / len(party_data)) * 100\n",
    "            all_party_truth_rates.append(truth_rate)\n",
    "    \n",
    "    if all_party_truth_rates:\n",
    "        axes[2,0].hist(all_party_truth_rates, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[2,0].set_title('Distribution of Truth Rates Across Parties', fontweight='bold')\n",
    "        axes[2,0].set_xlabel('Truth Rate (%)')\n",
    "        axes[2,0].set_ylabel('Number of Parties')\n",
    "        axes[2,0].axvline(np.mean(all_party_truth_rates), color='red', linestyle='--', label=f'Mean: {np.mean(all_party_truth_rates):.1f}%')\n",
    "        axes[2,0].legend()\n",
    "    else:\n",
    "        axes[2,0].text(0.5, 0.5, 'Insufficient party data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[2,0].set_title('Distribution of Truth Rates Across Parties', fontweight='bold')\n",
    "    \n",
    "    # 7. Subject matter popularity vs truth rate\n",
    "    if 'subject_truth_rates' in bias_analysis:\n",
    "        subject_df = bias_analysis['subject_truth_rates']\n",
    "        axes[2,1].scatter(subject_df['total_statements'], subject_df['high_truth_rate'],\n",
    "                         s=60, alpha=0.7, c='green')\n",
    "        \n",
    "        # Add subject labels for interesting points\n",
    "        for _, row in subject_df.iterrows():\n",
    "            if row['total_statements'] > 100 or row['high_truth_rate'] > 70 or row['high_truth_rate'] < 30:\n",
    "                axes[2,1].annotate(row['subject'][:15], xy=(row['total_statements'], row['high_truth_rate']), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        axes[2,1].set_xlabel('Number of Statements')\n",
    "        axes[2,1].set_ylabel('Truth Rate (%)')\n",
    "        axes[2,1].set_title('Subject Popularity vs Truth Rate', fontweight='bold')\n",
    "    else:\n",
    "        axes[2,1].text(0.5, 0.5, 'No subject data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[2,1].set_title('Subject Popularity vs Truth Rate', fontweight='bold')\n",
    "    \n",
    "    # 8. Bias summary metrics\n",
    "    # Calculate bias metrics\n",
    "    party_df = bias_analysis['party_truth_rates']\n",
    "    truth_rate_std = party_df['high_truth_rate'].std()\n",
    "    truth_rate_range = party_df['high_truth_rate'].max() - party_df['high_truth_rate'].min()\n",
    "    \n",
    "    metrics_text = f\"\"\"BIAS METRICS SUMMARY\n",
    "\n",
    "Truth Rate Standard Deviation: {truth_rate_std:.1f}%\n",
    "Truth Rate Range: {truth_rate_range:.1f}%\n",
    "\n",
    "Most Truthful Party:\n",
    "{party_df.loc[party_df['high_truth_rate'].idxmax(), 'party'][:20]}\n",
    "({party_df['high_truth_rate'].max():.1f}%)\n",
    "\n",
    "Least Truthful Party:\n",
    "{party_df.loc[party_df['high_truth_rate'].idxmin(), 'party'][:20]}\n",
    "({party_df['high_truth_rate'].min():.1f}%)\n",
    "\n",
    "Total Parties Analyzed: {len(party_df)}\n",
    "Total Statements: {party_df['total_statements'].sum():,}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[2,2].text(0.1, 0.9, metrics_text, transform=axes[2,2].transAxes, fontsize=11,\n",
    "                   verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[2,2].set_xlim(0, 1)\n",
    "    axes[2,2].set_ylim(0, 1)\n",
    "    axes[2,2].axis('off')\n",
    "    axes[2,2].set_title('Bias Analysis Summary', fontweight='bold')\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    axes[1,1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/day2_political_bias_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"âœ… Political bias analysis saved to 'results/plots/day2_political_bias_analysis.png'\")\n",
    "    plt.show()\n",
    "\n",
    "# Perform comprehensive political bias analysis\n",
    "bias_results = comprehensive_political_bias_analysis(df)\n",
    "\n",
    "# Create political bias visualizations\n",
    "create_political_bias_visualizations(df, bias_results)\n",
    "\n",
    "def create_advanced_text_visualizations(df):\n",
    "    \"\"\"Create advanced text analysis and word cloud visualizations\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ“ ADVANCED TEXT VISUALIZATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Prepare text data\n",
    "    df['statement_clean'] = df['statement'].fillna('').astype(str)\n",
    "    \n",
    "    # Create figure for text visualizations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "    fig.suptitle('Advanced Text Analysis Visualizations', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Word clouds by truth label\n",
    "    print(\"ğŸŒ¤ï¸ Creating word clouds by truth label...\")\n",
    "    \n",
    "    # True statements word cloud\n",
    "    true_text = ' '.join(df[df['label'] == 'true']['statement_clean'].values)\n",
    "    if len(true_text.strip()) > 0:\n",
    "        wordcloud_true = WordCloud(width=400, height=300, background_color='white',\n",
    "                                  colormap='Greens', max_words=50).generate(true_text)\n",
    "        axes[0,0].imshow(wordcloud_true, interpolation='bilinear')\n",
    "        axes[0,0].set_title('Word Cloud: TRUE Statements', fontweight='bold')\n",
    "        axes[0,0].axis('off')\n",
    "    else:\n",
    "        axes[0,0].text(0.5, 0.5, 'No true statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,0].set_title('Word Cloud: TRUE Statements', fontweight='bold')\n",
    "    \n",
    "    # False statements word cloud\n",
    "    false_text = ' '.join(df[df['label'] == 'false']['statement_clean'].values)\n",
    "    if len(false_text.strip()) > 0:\n",
    "        wordcloud_false = WordCloud(width=400, height=300, background_color='white',\n",
    "                                   colormap='Reds', max_words=50).generate(false_text)\n",
    "        axes[0,1].imshow(wordcloud_false, interpolation='bilinear')\n",
    "        axes[0,1].set_title('Word Cloud: FALSE Statements', fontweight='bold')\n",
    "        axes[0,1].axis('off')\n",
    "    else:\n",
    "        axes[0,1].text(0.5, 0.5, 'No false statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,1].set_title('Word Cloud: FALSE Statements', fontweight='bold')\n",
    "    \n",
    "    # Pants-fire statements word cloud\n",
    "    pants_fire_text = ' '.join(df[df['label'] == 'pants-fire']['statement_clean'].values)\n",
    "    if len(pants_fire_text.strip()) > 0:\n",
    "        wordcloud_pants = WordCloud(width=400, height=300, background_color='white',\n",
    "                                   colormap='OrRd', max_words=50).generate(pants_fire_text)\n",
    "        axes[0,2].imshow(wordcloud_pants, interpolation='bilinear')\n",
    "        axes[0,2].set_title('Word Cloud: PANTS-FIRE Statements', fontweight='bold')\n",
    "        axes[0,2].axis('off')\n",
    "    else:\n",
    "        axes[0,2].text(0.5, 0.5, 'No pants-fire statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,2].set_title('Word Cloud: PANTS-FIRE Statements', fontweight='bold')\n",
    "    \n",
    "    # 2. Most common words analysis\n",
    "    print(\"ğŸ“Š Analyzing most common words...\")\n",
    "    \n",
    "    # Extract common words for each category\n",
    "    def extract_common_words(text_series, top_n=15):\n",
    "        all_text = ' '.join(text_series.fillna('').astype(str))\n",
    "        # Simple word extraction\n",
    "        words = re.findall(r'\\b[a-zA-Z]{3,}\\b', all_text.lower())\n",
    "        # Remove common stop words\n",
    "        stop_words = {'the', 'and', 'that', 'have', 'for', 'not', 'with', 'you', 'this', \n",
    "                     'but', 'his', 'from', 'they', 'she', 'her', 'been', 'than', 'its', \n",
    "                     'are', 'was', 'will', 'would', 'could', 'should', 'said', 'says'}\n",
    "        words = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "        return Counter(words).most_common(top_n)\n",
    "    \n",
    "    # True statements common words\n",
    "    true_words = extract_common_words(df[df['label'] == 'true']['statement_clean'])\n",
    "    if true_words:\n",
    "        words, counts = zip(*true_words[:10])\n",
    "        axes[1,0].barh(range(len(words)), counts, color='green', alpha=0.7)\n",
    "        axes[1,0].set_yticks(range(len(words)))\n",
    "        axes[1,0].set_yticklabels(words)\n",
    "        axes[1,0].set_title('Most Common Words: TRUE Statements', fontweight='bold')\n",
    "        axes[1,0].set_xlabel('Frequency')\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'No true statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,0].set_title('Most Common Words: TRUE Statements', fontweight='bold')\n",
    "    \n",
    "    # False statements common words\n",
    "    false_words = extract_common_words(df[df['label'] == 'false']['statement_clean'])\n",
    "    if false_words:\n",
    "        words, counts = zip(*false_words[:10])\n",
    "        axes[1,1].barh(range(len(words)), counts, color='red', alpha=0.7)\n",
    "        axes[1,1].set_yticks(range(len(words)))\n",
    "        axes[1,1].set_yticklabels(words)\n",
    "        axes[1,1].set_title('Most Common Words: FALSE Statements', fontweight='bold')\n",
    "        axes[1,1].set_xlabel('Frequency')\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'No false statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,1].set_title('Most Common Words: FALSE Statements', fontweight='bold')\n",
    "    \n",
    "    # 3. Text length patterns\n",
    "    print(\"ğŸ“ Analyzing text length patterns...\")\n",
    "    \n",
    "    # Create text length distribution by label\n",
    "    labels_for_length = ['true', 'false', 'mostly-true', 'barely-true']\n",
    "    colors = ['green', 'red', 'blue', 'orange']\n",
    "    \n",
    "    has_data = False\n",
    "    for label, color in zip(labels_for_length, colors):\n",
    "        if label in df['label'].values:\n",
    "            lengths = df[df['label'] == label]['text_length']\n",
    "            axes[1,2].hist(lengths, bins=20, alpha=0.6, label=label, color=color)\n",
    "            has_data = True\n",
    "    \n",
    "    if has_data:\n",
    "        axes[1,2].set_xlabel('Text Length (characters)')\n",
    "        axes[1,2].set_ylabel('Frequency')\n",
    "        axes[1,2].set_title('Text Length Distribution by Label', fontweight='bold')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].set_xlim(0, 500)  # Focus on reasonable range\n",
    "    else:\n",
    "        axes[1,2].text(0.5, 0.5, 'No text length data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,2].set_title('Text Length Distribution by Label', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/day2_advanced_text_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"âœ… Advanced text visualizations saved to 'results/plots/day2_advanced_text_visualizations.png'\")\n",
    "    plt.show()\n",
    "\n",
    "def create_interactive_dashboard_data(df, bias_results):\n",
    "    \"\"\"Prepare data for interactive dashboard creation\"\"\"\n",
    "    print(\"\\nğŸ›ï¸ Preparing interactive dashboard data...\")\n",
    "    \n",
    "    # Create summary statistics for dashboard\n",
    "    dashboard_data = {\n",
    "        'overview': {\n",
    "            'total_statements': len(df),\n",
    "            'unique_speakers': df['speaker'].nunique(),\n",
    "            'unique_subjects': df['subject'].nunique(),\n",
    "            'unique_parties': df['party_affiliation'].nunique(),\n",
    "            'truth_rate_overall': (df['label'].isin(['true', 'mostly-true']).sum() / len(df)) * 100\n",
    "        },\n",
    "        'party_analysis': bias_results['party_truth_rates'].to_dict('records'),\n",
    "        'subject_analysis': bias_results['subject_truth_rates'].to_dict('records'),\n",
    "        'label_distribution': df['label'].value_counts().to_dict(),\n",
    "        'text_stats': {\n",
    "            'avg_length': df['text_length'].mean(),\n",
    "            'length_by_label': df.groupby('label')['text_length'].mean().to_dict()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save dashboard data\n",
    "    with open('results/reports/dashboard_data.json', 'w') as f:\n",
    "        json.dump(dashboard_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"âœ… Dashboard data saved to 'results/reports/dashboard_data.json'\")\n",
    "    \n",
    "    return dashboard_data\n",
    "\n",
    "# Create advanced text visualizations\n",
    "create_advanced_text_visualizations(df)\n",
    "\n",
    "# Prepare interactive dashboard data\n",
    "dashboard_data = create_interactive_dashboard_data(df, bias_results)\n",
    "\n",
    "def generate_final_day2_summary(df, bias_results, dashboard_data):\n",
    "    \"\"\"Generate final comprehensive Day 2 summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“‹ FINAL DAY 2 COMPREHENSIVE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"ğŸ¯ ACHIEVEMENTS TODAY:\")\n",
    "    print(\"   âœ… Advanced linguistic feature extraction\")\n",
    "    print(\"   âœ… Comprehensive statistical significance testing\")\n",
    "    print(\"   âœ… Detailed political bias analysis\")\n",
    "    print(\"   âœ… Advanced text visualizations and word clouds\")\n",
    "    print(\"   âœ… Interactive dashboard data preparation\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š KEY INSIGHTS DISCOVERED:\")\n",
    "    \n",
    "    # Political bias insights\n",
    "    party_df = bias_results['party_truth_rates']\n",
    "    if not party_df.empty:\n",
    "        max_truth_party = party_df.loc[party_df['high_truth_rate'].idxmax()]\n",
    "        min_truth_party = party_df.loc[party_df['high_truth_rate'].idxmin()]\n",
    "        \n",
    "        print(f\"   ğŸ›ï¸ Political Bias:\")\n",
    "        print(f\"      â€¢ Highest truth rate: {max_truth_party['party']} ({max_truth_party['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      â€¢ Lowest truth rate: {min_truth_party['party']} ({min_truth_party['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      â€¢ Truth rate spread: {party_df['high_truth_rate'].max() - party_df['high_truth_rate'].min():.1f} percentage points\")\n",
    "    else:\n",
    "        print(\"   ğŸ›ï¸ Political Bias: No party data available\")\n",
    "    \n",
    "    # Subject matter insights\n",
    "    subject_df = bias_results['subject_truth_rates']\n",
    "    if not subject_df.empty:\n",
    "        max_truth_subject = subject_df.loc[subject_df['high_truth_rate'].idxmax()]\n",
    "        min_truth_subject = subject_df.loc[subject_df['high_truth_rate'].idxmin()]\n",
    "        \n",
    "        print(f\"   ğŸ“š Subject Matter Bias:\")\n",
    "        print(f\"      â€¢ Most truthful subject: {max_truth_subject['subject'][:30]}... ({max_truth_subject['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      â€¢ Least truthful subject: {min_truth_subject['subject'][:30]}... ({min_truth_subject['high_truth_rate']:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   ğŸ“š Subject Matter Bias: No subject data available\")\n",
    "    \n",
    "    # Text characteristics\n",
    "    print(f\"   ğŸ“ Text Characteristics:\")\n",
    "    print(f\"      â€¢ Average statement length: {df['text_length'].mean():.0f} characters\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ FILES GENERATED TODAY:\")\n",
    "    files_generated = [\n",
    "        \"results/plots/day2_political_bias_analysis.png\",\n",
    "        \"results/plots/day2_advanced_text_visualizations.png\",\n",
    "        \"results/reports/dashboard_data.json\",\n",
    "        \"data/processed/liar_dataset_processed.csv\"\n",
    "    ]\n",
    "    \n",
    "    for file in files_generated:\n",
    "        print(f\"   ğŸ“„ {file}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ PREPARATION FOR DAY 3:\")\n",
    "    print(\"   ğŸ“‹ Data profiling reports ready\")\n",
    "    print(\"   ğŸ“Š Advanced visualizations completed\")\n",
    "    print(\"   ğŸ›ï¸ Dashboard data prepared\")\n",
    "    print(\"   ğŸ“ˆ Statistical analysis comprehensive\")\n",
    "    print(\"   ğŸ›ï¸ Bias analysis thorough\")\n",
    "    \n",
    "    print(f\"\\nâ° DAY 2 TIMELINE COMPLETED:\")\n",
    "    print(\"   âœ… 9:00-11:00 AM: Advanced EDA & Linguistic Analysis\")\n",
    "    print(\"   âœ… 11:00-1:00 PM: Statistical Testing & Correlation Analysis\")\n",
    "    print(\"   âœ… 2:00-4:00 PM: Political Bias & Advanced Visualizations\")\n",
    "    \n",
    "    return {\n",
    "        'completion_status': 'Day 2 Complete',\n",
    "        'insights_generated': 4,\n",
    "        'files_generated': len(files_generated),\n",
    "        'next_phase': 'Day 3: Final Documentation & Reporting'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6939f14-c76e-4fa1-940e-febd8dc20a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
