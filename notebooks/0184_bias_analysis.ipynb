{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecaf693-a92a-4419-a291-508ae970cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Processed data not found. Loading raw data...\n",
      "‚ùå Error loading raw data: [Errno 2] No such file or directory: 'data/raw/liar_dataset/train.tsv'\n",
      "Please download the LIAR dataset and place it in 'data/raw/liar_dataset/'\n",
      "Dataset available at: https://www.cs.ucsb.edu/~william/data/liar_dataset.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/liar_dataset/train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/processed/liar_dataset_processed.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Loaded processed dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/liar_dataset_processed.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Loaded processed dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     df = \u001b[43mload_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Rest of your original code continues from here...\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomprehensive_political_bias_analysis\u001b[39m(df):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mload_raw_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Load train, test and validation datasets\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/raw/liar_dataset/train.tsv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     test_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/raw/liar_dataset/test.tsv\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mNone\u001b[39;00m, names=columns)\n\u001b[32m     35\u001b[39m     valid_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/raw/liar_dataset/valid.tsv\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, header=\u001b[38;5;28;01mNone\u001b[39;00m, names=columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/raw/liar_dataset/train.tsv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('data/raw/liar_dataset', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('results/plots', exist_ok=True)\n",
    "os.makedirs('results/reports', exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üé≠ BIAS ANALYSIS & ADVANCED VISUALIZATIONS\")\n",
    "print(\"Member: ITBIN-2211-0184\")\n",
    "print(\"Time: 2:00 PM - 4:00 PM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Download and extract the dataset if missing\n",
    "def download_dataset():\n",
    "    dataset_url = \"https://raw.githubusercontent.com/msantinelli/fake-news-detection/main/data/raw/liar_dataset.zip\"\n",
    "    print(f\"‚ö†Ô∏è Dataset not found. Downloading from {dataset_url}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(dataset_url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        \n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "            # Extract directly to data/raw directory\n",
    "            zip_ref.extractall('data/raw')\n",
    "            print(\"‚úÖ Dataset downloaded and extracted successfully\")\n",
    "            \n",
    "            # Move files to liar_dataset directory\n",
    "            for file in ['train.tsv', 'test.tsv', 'valid.tsv']:\n",
    "                src = f'data/raw/{file}'\n",
    "                dst = f'data/raw/liar_dataset/{file}'\n",
    "                if os.path.exists(src):\n",
    "                    shutil.move(src, dst)\n",
    "            \n",
    "            print(\"üìÅ Files moved to data/raw/liar_dataset/\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "# Load the dataset from raw files\n",
    "def load_raw_dataset():\n",
    "    # Define column names for LIAR dataset\n",
    "    columns = [\n",
    "        'id', 'label', 'statement', 'subject', 'speaker', 'speaker_job', \n",
    "        'state_info', 'party_affiliation', \n",
    "        'barely_true_counts', 'false_counts', 'half_true_counts', \n",
    "        'mostly_true_counts', 'pants_on_fire_counts'\n",
    "    ]\n",
    "    \n",
    "    # Check if files exist, download if missing\n",
    "    required_files = [\n",
    "        'data/raw/liar_dataset/train.tsv',\n",
    "        'data/raw/liar_dataset/test.tsv',\n",
    "        'data/raw/liar_dataset/valid.tsv'\n",
    "    ]\n",
    "    \n",
    "    if not all(os.path.exists(f) for f in required_files):\n",
    "        if not download_dataset():\n",
    "            raise FileNotFoundError(\"Could not load dataset files\")\n",
    "    \n",
    "    # Load train, test and validation datasets\n",
    "    try:\n",
    "        train_df = pd.read_csv('data/raw/liar_dataset/train.tsv', sep='\\t', header=None, names=columns)\n",
    "        test_df = pd.read_csv('data/raw/liar_dataset/test.tsv', sep='\\t', header=None, names=columns)\n",
    "        valid_df = pd.read_csv('data/raw/liar_dataset/valid.tsv', sep='\\t', header=None, names=columns)\n",
    "        \n",
    "        # Add split information\n",
    "        train_df['split'] = 'train'\n",
    "        test_df['split'] = 'test'\n",
    "        valid_df['split'] = 'valid'\n",
    "        \n",
    "        # Combine datasets\n",
    "        df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        print(f\"‚úÖ Loaded raw dataset: {df.shape}\")\n",
    "        \n",
    "        # Minimal preprocessing\n",
    "        df['text_length'] = df['statement'].apply(len)\n",
    "        df['party_affiliation'] = df['party_affiliation'].fillna('unknown').str.lower().str.strip()\n",
    "        df['subject'] = df['subject'].fillna('unknown').str.lower().str.strip()\n",
    "        df['speaker_job'] = df['speaker_job'].fillna('unknown')\n",
    "        \n",
    "        # Create simplified labels\n",
    "        label_mapping = {\n",
    "            'true': 'true',\n",
    "            'mostly-true': 'mostly-true',\n",
    "            'half-true': 'half-true',\n",
    "            'barely-true': 'barely-true',\n",
    "            'false': 'false',\n",
    "            'pants-fire': 'pants-fire'\n",
    "        }\n",
    "        df['label'] = df['label'].map(label_mapping).fillna('unknown')\n",
    "        \n",
    "        # Save processed data for future use\n",
    "        df.to_csv('data/processed/liar_dataset_processed.csv', index=False)\n",
    "        print(\"üíæ Saved processed data to 'data/processed/liar_dataset_processed.csv'\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading raw data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Try to load processed data\n",
    "try:\n",
    "    df = pd.read_csv('data/processed/liar_dataset_processed.csv')\n",
    "    print(f\"‚úÖ Loaded processed dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    df = load_raw_dataset()\n",
    "\n",
    "def comprehensive_political_bias_analysis(df):\n",
    "    \"\"\"Perform comprehensive political bias analysis\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üèõÔ∏è COMPREHENSIVE POLITICAL BIAS ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    bias_analysis = {}\n",
    "    \n",
    "    # 1. Truth rate by party affiliation\n",
    "    print(\"1Ô∏è‚É£ Truth Rate Analysis by Party Affiliation\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Define truth categories\n",
    "    high_truth = ['true', 'mostly-true']\n",
    "    low_truth = ['false', 'pants-fire']\n",
    "    \n",
    "    # Calculate truth rates by party\n",
    "    party_stats = []\n",
    "    top_parties = df['party_affiliation'].value_counts().head(10).index\n",
    "    \n",
    "    for party in top_parties:\n",
    "        party_data = df[df['party_affiliation'] == party]\n",
    "        total_statements = len(party_data)\n",
    "        \n",
    "        high_truth_count = party_data['label'].isin(high_truth).sum()\n",
    "        low_truth_count = party_data['label'].isin(low_truth).sum()\n",
    "        \n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        low_truth_rate = (low_truth_count / total_statements) * 100\n",
    "        \n",
    "        party_stats.append({\n",
    "            'party': party,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "            'low_truth_rate': low_truth_rate,\n",
    "            'high_truth_count': high_truth_count,\n",
    "            'low_truth_count': low_truth_count\n",
    "        })\n",
    "        \n",
    "        print(f\"{party:20} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}% | False: {low_truth_rate:5.1f}%\")\n",
    "    \n",
    "    party_df = pd.DataFrame(party_stats)\n",
    "    bias_analysis['party_truth_rates'] = party_df\n",
    "    \n",
    "    # 2. Subject matter bias analysis\n",
    "    print(f\"\\n2Ô∏è‚É£ Subject Matter Bias Analysis\")\n",
    "    print(\"-\" * 32)\n",
    "    \n",
    "    subject_stats = []\n",
    "    top_subjects = df['subject'].value_counts().head(10).index\n",
    "    \n",
    "    for subject in top_subjects:\n",
    "        subject_data = df[df['subject'] == subject]\n",
    "        total_statements = len(subject_data)\n",
    "        \n",
    "        high_truth_count = subject_data['label'].isin(high_truth).sum()\n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        \n",
    "        subject_stats.append({\n",
    "            'subject': subject,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "        })\n",
    "        \n",
    "        print(f\"{subject:25} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    subject_df = pd.DataFrame(subject_stats)\n",
    "    bias_analysis['subject_truth_rates'] = subject_df\n",
    "    \n",
    "    # 3. Speaker role bias analysis\n",
    "    print(f\"\\n3Ô∏è‚É£ Speaker Role Bias Analysis\")\n",
    "    print(\"-\" * 28)\n",
    "    \n",
    "    # Clean and analyze speaker jobs\n",
    "    df['speaker_job_clean'] = df['speaker_job'].fillna('Unknown').str.title()\n",
    "    \n",
    "    role_stats = []\n",
    "    top_roles = df['speaker_job_clean'].value_counts().head(10).index\n",
    "    \n",
    "    for role in top_roles:\n",
    "        role_data = df[df['speaker_job_clean'] == role]\n",
    "        total_statements = len(role_data)\n",
    "        \n",
    "        if total_statements >= 10:  # Only analyze roles with sufficient data\n",
    "            high_truth_count = role_data['label'].isin(high_truth).sum()\n",
    "            high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "            \n",
    "            role_stats.append({\n",
    "                'role': role,\n",
    "                'total_statements': total_statements,\n",
    "                'high_truth_rate': high_truth_rate,\n",
    "            })\n",
    "            \n",
    "            print(f\"{role:25} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    role_df = pd.DataFrame(role_stats)\n",
    "    bias_analysis['role_truth_rates'] = role_df\n",
    "    \n",
    "    # 4. Temporal bias analysis (by data split as proxy)\n",
    "    print(f\"\\n4Ô∏è‚É£ Data Split Analysis\")\n",
    "    print(\"-\" * 22)\n",
    "    \n",
    "    split_stats = []\n",
    "    for split in df['split'].unique():\n",
    "        split_data = df[df['split'] == split]\n",
    "        total_statements = len(split_data)\n",
    "        \n",
    "        high_truth_count = split_data['label'].isin(high_truth).sum()\n",
    "        high_truth_rate = (high_truth_count / total_statements) * 100\n",
    "        \n",
    "        split_stats.append({\n",
    "            'split': split,\n",
    "            'total_statements': total_statements,\n",
    "            'high_truth_rate': high_truth_rate,\n",
    "        })\n",
    "        \n",
    "        print(f\"{split:10} | {total_statements:4d} statements | Truth: {high_truth_rate:5.1f}%\")\n",
    "    \n",
    "    bias_analysis['split_analysis'] = pd.DataFrame(split_stats)\n",
    "    \n",
    "    return bias_analysis\n",
    "\n",
    "def create_political_bias_visualizations(df, bias_analysis):\n",
    "    \"\"\"Create comprehensive political bias visualizations\"\"\"\n",
    "    print(\"\\nüìä Creating political bias visualizations...\")\n",
    "    \n",
    "    # Create large figure with multiple subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(22, 18))\n",
    "    fig.suptitle('Comprehensive Political Bias Analysis', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # 1. Party truth rates (horizontal bar chart)\n",
    "    party_df = bias_analysis['party_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "    colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(party_df)))\n",
    "    \n",
    "    bars = axes[0,0].barh(range(len(party_df)), party_df['high_truth_rate'], color=colors)\n",
    "    axes[0,0].set_yticks(range(len(party_df)))\n",
    "    axes[0,0].set_yticklabels(party_df['party'], fontsize=10)\n",
    "    axes[0,0].set_title('Truth Rate by Party Affiliation', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('High Truth Rate (%)')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, rate) in enumerate(zip(bars, party_df['high_truth_rate'])):\n",
    "        axes[0,0].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{rate:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    # 2. Subject matter truth rates\n",
    "    subject_df = bias_analysis['subject_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "    colors = plt.cm.Greens(np.linspace(0.3, 0.9, len(subject_df)))\n",
    "    \n",
    "    bars = axes[0,1].barh(range(len(subject_df)), subject_df['high_truth_rate'], color=colors)\n",
    "    axes[0,1].set_yticks(range(len(subject_df)))\n",
    "    axes[0,1].set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in subject_df['subject']], fontsize=9)\n",
    "    axes[0,1].set_title('Truth Rate by Subject Matter', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('High Truth Rate (%)')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, rate) in enumerate(zip(bars, subject_df['high_truth_rate'])):\n",
    "        axes[0,1].text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{rate:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    # 3. Speaker role analysis\n",
    "    if len(bias_analysis['role_truth_rates']) > 0:\n",
    "        role_df = bias_analysis['role_truth_rates'].sort_values('high_truth_rate', ascending=True)\n",
    "        colors = plt.cm.Oranges(np.linspace(0.3, 0.9, len(role_df)))\n",
    "        \n",
    "        bars = axes[0,2].barh(range(len(role_df)), role_df['high_truth_rate'], color=colors)\n",
    "        axes[0,2].set_yticks(range(len(role_df)))\n",
    "        axes[0,2].set_yticklabels([r[:15] + '...' if len(r) > 15 else r for r in role_df['role']], fontsize=9)\n",
    "        axes[0,2].set_title('Truth Rate by Speaker Role', fontweight='bold')\n",
    "        axes[0,2].set_xlabel('High Truth Rate (%)')\n",
    "    else:\n",
    "        axes[0,2].axis('off')\n",
    "    \n",
    "    # 4. Party vs Subject heatmap (truth rates)\n",
    "    party_subject_pivot = df.groupby(['party_affiliation', 'subject']).apply(\n",
    "        lambda x: (x['label'].isin(['true', 'mostly-true']).sum() / len(x)) * 100\n",
    "    ).reset_index(name='truth_rate')\n",
    "    \n",
    "    # Filter for top parties and subjects\n",
    "    top_parties = df['party_affiliation'].value_counts().head(6).index\n",
    "    top_subjects = df['subject'].value_counts().head(6).index\n",
    "    \n",
    "    pivot_filtered = party_subject_pivot[\n",
    "        (party_subject_pivot['party_affiliation'].isin(top_parties)) &\n",
    "        (party_subject_pivot['subject'].isin(top_subjects))\n",
    "    ]\n",
    "    \n",
    "    if not pivot_filtered.empty:\n",
    "        pivot_table = pivot_filtered.pivot(index='party_affiliation', columns='subject', values='truth_rate')\n",
    "        sns.heatmap(pivot_table, annot=True, cmap='RdYlGn', center=50, ax=axes[1,0], fmt='.1f')\n",
    "        axes[1,0].set_title('Truth Rate Heatmap: Party vs Subject', fontweight='bold')\n",
    "        axes[1,0].set_ylabel('Party Affiliation')\n",
    "        axes[1,0].set_xlabel('Subject')\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'Insufficient data for heatmap', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,0].set_title('Truth Rate Heatmap: Party vs Subject', fontweight='bold')\n",
    "    \n",
    "    # 5. Statement distribution by party\n",
    "    party_counts = df['party_affiliation'].value_counts().head(8)\n",
    "    axes[1,2].pie(party_counts.values, labels=[p[:10] + '...' if len(p) > 10 else p for p in party_counts.index],\n",
    "                  autopct='%1.1f%%', startangle=90)\n",
    "    axes[1,2].set_title('Statement Distribution by Party', fontweight='bold')\n",
    "    \n",
    "    # 6. Truth rate distribution across all parties\n",
    "    all_party_truth_rates = []\n",
    "    for party in df['party_affiliation'].unique():\n",
    "        party_data = df[df['party_affiliation'] == party]\n",
    "        if len(party_data) >= 5:  # Minimum statements for reliable rate\n",
    "            truth_rate = (party_data['label'].isin(['true', 'mostly-true']).sum() / len(party_data)) * 100\n",
    "            all_party_truth_rates.append(truth_rate)\n",
    "    \n",
    "    if all_party_truth_rates:\n",
    "        axes[2,0].hist(all_party_truth_rates, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[2,0].set_title('Distribution of Truth Rates Across Parties', fontweight='bold')\n",
    "        axes[2,0].set_xlabel('Truth Rate (%)')\n",
    "        axes[2,0].set_ylabel('Number of Parties')\n",
    "        axes[2,0].axvline(np.mean(all_party_truth_rates), color='red', linestyle='--', label=f'Mean: {np.mean(all_party_truth_rates):.1f}%')\n",
    "        axes[2,0].legend()\n",
    "    else:\n",
    "        axes[2,0].text(0.5, 0.5, 'Insufficient party data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[2,0].set_title('Distribution of Truth Rates Across Parties', fontweight='bold')\n",
    "    \n",
    "    # 7. Subject matter popularity vs truth rate\n",
    "    if 'subject_truth_rates' in bias_analysis:\n",
    "        subject_df = bias_analysis['subject_truth_rates']\n",
    "        axes[2,1].scatter(subject_df['total_statements'], subject_df['high_truth_rate'],\n",
    "                         s=60, alpha=0.7, c='green')\n",
    "        \n",
    "        # Add subject labels for interesting points\n",
    "        for _, row in subject_df.iterrows():\n",
    "            if row['total_statements'] > 100 or row['high_truth_rate'] > 70 or row['high_truth_rate'] < 30:\n",
    "                axes[2,1].annotate(row['subject'][:15], xy=(row['total_statements'], row['high_truth_rate']), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        axes[2,1].set_xlabel('Number of Statements')\n",
    "        axes[2,1].set_ylabel('Truth Rate (%)')\n",
    "        axes[2,1].set_title('Subject Popularity vs Truth Rate', fontweight='bold')\n",
    "    else:\n",
    "        axes[2,1].text(0.5, 0.5, 'No subject data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[2,1].set_title('Subject Popularity vs Truth Rate', fontweight='bold')\n",
    "    \n",
    "    # 8. Bias summary metrics\n",
    "    # Calculate bias metrics\n",
    "    party_df = bias_analysis['party_truth_rates']\n",
    "    truth_rate_std = party_df['high_truth_rate'].std()\n",
    "    truth_rate_range = party_df['high_truth_rate'].max() - party_df['high_truth_rate'].min()\n",
    "    \n",
    "    metrics_text = f\"\"\"BIAS METRICS SUMMARY\n",
    "\n",
    "Truth Rate Standard Deviation: {truth_rate_std:.1f}%\n",
    "Truth Rate Range: {truth_rate_range:.1f}%\n",
    "\n",
    "Most Truthful Party:\n",
    "{party_df.loc[party_df['high_truth_rate'].idxmax(), 'party'][:20]}\n",
    "({party_df['high_truth_rate'].max():.1f}%)\n",
    "\n",
    "Least Truthful Party:\n",
    "{party_df.loc[party_df['high_truth_rate'].idxmin(), 'party'][:20]}\n",
    "({party_df['high_truth_rate'].min():.1f}%)\n",
    "\n",
    "Total Parties Analyzed: {len(party_df)}\n",
    "Total Statements: {party_df['total_statements'].sum():,}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[2,2].text(0.1, 0.9, metrics_text, transform=axes[2,2].transAxes, fontsize=11,\n",
    "                   verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[2,2].set_xlim(0, 1)\n",
    "    axes[2,2].set_ylim(0, 1)\n",
    "    axes[2,2].axis('off')\n",
    "    axes[2,2].set_title('Bias Analysis Summary', fontweight='bold')\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    axes[1,1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/day2_political_bias_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Political bias analysis saved to 'results/plots/day2_political_bias_analysis.png'\")\n",
    "    plt.show()\n",
    "\n",
    "# Perform comprehensive political bias analysis\n",
    "bias_results = comprehensive_political_bias_analysis(df)\n",
    "\n",
    "# Create political bias visualizations\n",
    "create_political_bias_visualizations(df, bias_results)\n",
    "\n",
    "def create_advanced_text_visualizations(df):\n",
    "    \"\"\"Create advanced text analysis and word cloud visualizations\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìù ADVANCED TEXT VISUALIZATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Prepare text data\n",
    "    df['statement_clean'] = df['statement'].fillna('').astype(str)\n",
    "    \n",
    "    # Create figure for text visualizations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "    fig.suptitle('Advanced Text Analysis Visualizations', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Word clouds by truth label\n",
    "    print(\"üå§Ô∏è Creating word clouds by truth label...\")\n",
    "    \n",
    "    # True statements word cloud\n",
    "    true_text = ' '.join(df[df['label'] == 'true']['statement_clean'].values)\n",
    "    if len(true_text.strip()) > 0:\n",
    "        wordcloud_true = WordCloud(width=400, height=300, background_color='white',\n",
    "                                  colormap='Greens', max_words=50).generate(true_text)\n",
    "        axes[0,0].imshow(wordcloud_true, interpolation='bilinear')\n",
    "        axes[0,0].set_title('Word Cloud: TRUE Statements', fontweight='bold')\n",
    "        axes[0,0].axis('off')\n",
    "    else:\n",
    "        axes[0,0].text(0.5, 0.5, 'No true statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,0].set_title('Word Cloud: TRUE Statements', fontweight='bold')\n",
    "    \n",
    "    # False statements word cloud\n",
    "    false_text = ' '.join(df[df['label'] == 'false']['statement_clean'].values)\n",
    "    if len(false_text.strip()) > 0:\n",
    "        wordcloud_false = WordCloud(width=400, height=300, background_color='white',\n",
    "                                   colormap='Reds', max_words=50).generate(false_text)\n",
    "        axes[0,1].imshow(wordcloud_false, interpolation='bilinear')\n",
    "        axes[0,1].set_title('Word Cloud: FALSE Statements', fontweight='bold')\n",
    "        axes[0,1].axis('off')\n",
    "    else:\n",
    "        axes[0,1].text(0.5, 0.5, 'No false statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,1].set_title('Word Cloud: FALSE Statements', fontweight='bold')\n",
    "    \n",
    "    # Pants-fire statements word cloud\n",
    "    pants_fire_text = ' '.join(df[df['label'] == 'pants-fire']['statement_clean'].values)\n",
    "    if len(pants_fire_text.strip()) > 0:\n",
    "        wordcloud_pants = WordCloud(width=400, height=300, background_color='white',\n",
    "                                   colormap='OrRd', max_words=50).generate(pants_fire_text)\n",
    "        axes[0,2].imshow(wordcloud_pants, interpolation='bilinear')\n",
    "        axes[0,2].set_title('Word Cloud: PANTS-FIRE Statements', fontweight='bold')\n",
    "        axes[0,2].axis('off')\n",
    "    else:\n",
    "        axes[0,2].text(0.5, 0.5, 'No pants-fire statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[0,2].set_title('Word Cloud: PANTS-FIRE Statements', fontweight='bold')\n",
    "    \n",
    "    # 2. Most common words analysis\n",
    "    print(\"üìä Analyzing most common words...\")\n",
    "    \n",
    "    # Extract common words for each category\n",
    "    def extract_common_words(text_series, top_n=15):\n",
    "        all_text = ' '.join(text_series.fillna('').astype(str))\n",
    "        # Simple word extraction\n",
    "        words = re.findall(r'\\b[a-zA-Z]{3,}\\b', all_text.lower())\n",
    "        # Remove common stop words\n",
    "        stop_words = {'the', 'and', 'that', 'have', 'for', 'not', 'with', 'you', 'this', \n",
    "                     'but', 'his', 'from', 'they', 'she', 'her', 'been', 'than', 'its', \n",
    "                     'are', 'was', 'will', 'would', 'could', 'should', 'said', 'says'}\n",
    "        words = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "        return Counter(words).most_common(top_n)\n",
    "    \n",
    "    # True statements common words\n",
    "    true_words = extract_common_words(df[df['label'] == 'true']['statement_clean'])\n",
    "    if true_words:\n",
    "        words, counts = zip(*true_words[:10])\n",
    "        axes[1,0].barh(range(len(words)), counts, color='green', alpha=0.7)\n",
    "        axes[1,0].set_yticks(range(len(words)))\n",
    "        axes[1,0].set_yticklabels(words)\n",
    "        axes[1,0].set_title('Most Common Words: TRUE Statements', fontweight='bold')\n",
    "        axes[1,0].set_xlabel('Frequency')\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'No true statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,0].set_title('Most Common Words: TRUE Statements', fontweight='bold')\n",
    "    \n",
    "    # False statements common words\n",
    "    false_words = extract_common_words(df[df['label'] == 'false']['statement_clean'])\n",
    "    if false_words:\n",
    "        words, counts = zip(*false_words[:10])\n",
    "        axes[1,1].barh(range(len(words)), counts, color='red', alpha=0.7)\n",
    "        axes[1,1].set_yticks(range(len(words)))\n",
    "        axes[1,1].set_yticklabels(words)\n",
    "        axes[1,1].set_title('Most Common Words: FALSE Statements', fontweight='bold')\n",
    "        axes[1,1].set_xlabel('Frequency')\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'No false statements', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,1].set_title('Most Common Words: FALSE Statements', fontweight='bold')\n",
    "    \n",
    "    # 3. Text length patterns\n",
    "    print(\"üìè Analyzing text length patterns...\")\n",
    "    \n",
    "    # Create text length distribution by label\n",
    "    labels_for_length = ['true', 'false', 'mostly-true', 'barely-true']\n",
    "    colors = ['green', 'red', 'blue', 'orange']\n",
    "    \n",
    "    has_data = False\n",
    "    for label, color in zip(labels_for_length, colors):\n",
    "        if label in df['label'].values:\n",
    "            lengths = df[df['label'] == label]['text_length']\n",
    "            axes[1,2].hist(lengths, bins=20, alpha=0.6, label=label, color=color)\n",
    "            has_data = True\n",
    "    \n",
    "    if has_data:\n",
    "        axes[1,2].set_xlabel('Text Length (characters)')\n",
    "        axes[1,2].set_ylabel('Frequency')\n",
    "        axes[1,2].set_title('Text Length Distribution by Label', fontweight='bold')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].set_xlim(0, 500)  # Focus on reasonable range\n",
    "    else:\n",
    "        axes[1,2].text(0.5, 0.5, 'No text length data', \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "        axes[1,2].set_title('Text Length Distribution by Label', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/day2_advanced_text_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Advanced text visualizations saved to 'results/plots/day2_advanced_text_visualizations.png'\")\n",
    "    plt.show()\n",
    "\n",
    "def create_interactive_dashboard_data(df, bias_results):\n",
    "    \"\"\"Prepare data for interactive dashboard creation\"\"\"\n",
    "    print(\"\\nüéõÔ∏è Preparing interactive dashboard data...\")\n",
    "    \n",
    "    # Create summary statistics for dashboard\n",
    "    dashboard_data = {\n",
    "        'overview': {\n",
    "            'total_statements': len(df),\n",
    "            'unique_speakers': df['speaker'].nunique(),\n",
    "            'unique_subjects': df['subject'].nunique(),\n",
    "            'unique_parties': df['party_affiliation'].nunique(),\n",
    "            'truth_rate_overall': (df['label'].isin(['true', 'mostly-true']).sum() / len(df)) * 100\n",
    "        },\n",
    "        'party_analysis': bias_results['party_truth_rates'].to_dict('records'),\n",
    "        'subject_analysis': bias_results['subject_truth_rates'].to_dict('records'),\n",
    "        'label_distribution': df['label'].value_counts().to_dict(),\n",
    "        'text_stats': {\n",
    "            'avg_length': df['text_length'].mean(),\n",
    "            'length_by_label': df.groupby('label')['text_length'].mean().to_dict()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save dashboard data\n",
    "    with open('results/reports/dashboard_data.json', 'w') as f:\n",
    "        json.dump(dashboard_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"‚úÖ Dashboard data saved to 'results/reports/dashboard_data.json'\")\n",
    "    \n",
    "    return dashboard_data\n",
    "\n",
    "# Create advanced text visualizations\n",
    "create_advanced_text_visualizations(df)\n",
    "\n",
    "# Prepare interactive dashboard data\n",
    "dashboard_data = create_interactive_dashboard_data(df, bias_results)\n",
    "\n",
    "def generate_final_day2_summary(df, bias_results, dashboard_data):\n",
    "    \"\"\"Generate final comprehensive Day 2 summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã FINAL DAY 2 COMPREHENSIVE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"üéØ ACHIEVEMENTS TODAY:\")\n",
    "    print(\"   ‚úÖ Advanced linguistic feature extraction\")\n",
    "    print(\"   ‚úÖ Comprehensive statistical significance testing\")\n",
    "    print(\"   ‚úÖ Detailed political bias analysis\")\n",
    "    print(\"   ‚úÖ Advanced text visualizations and word clouds\")\n",
    "    print(\"   ‚úÖ Interactive dashboard data preparation\")\n",
    "    \n",
    "    print(f\"\\nüìä KEY INSIGHTS DISCOVERED:\")\n",
    "    \n",
    "    # Political bias insights\n",
    "    party_df = bias_results['party_truth_rates']\n",
    "    if not party_df.empty:\n",
    "        max_truth_party = party_df.loc[party_df['high_truth_rate'].idxmax()]\n",
    "        min_truth_party = party_df.loc[party_df['high_truth_rate'].idxmin()]\n",
    "        \n",
    "        print(f\"   üèõÔ∏è Political Bias:\")\n",
    "        print(f\"      ‚Ä¢ Highest truth rate: {max_truth_party['party']} ({max_truth_party['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      ‚Ä¢ Lowest truth rate: {min_truth_party['party']} ({min_truth_party['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      ‚Ä¢ Truth rate spread: {party_df['high_truth_rate'].max() - party_df['high_truth_rate'].min():.1f} percentage points\")\n",
    "    else:\n",
    "        print(\"   üèõÔ∏è Political Bias: No party data available\")\n",
    "    \n",
    "    # Subject matter insights\n",
    "    subject_df = bias_results['subject_truth_rates']\n",
    "    if not subject_df.empty:\n",
    "        max_truth_subject = subject_df.loc[subject_df['high_truth_rate'].idxmax()]\n",
    "        min_truth_subject = subject_df.loc[subject_df['high_truth_rate'].idxmin()]\n",
    "        \n",
    "        print(f\"   üìö Subject Matter Bias:\")\n",
    "        print(f\"      ‚Ä¢ Most truthful subject: {max_truth_subject['subject'][:30]}... ({max_truth_subject['high_truth_rate']:.1f}%)\")\n",
    "        print(f\"      ‚Ä¢ Least truthful subject: {min_truth_subject['subject'][:30]}... ({min_truth_subject['high_truth_rate']:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   üìö Subject Matter Bias: No subject data available\")\n",
    "    \n",
    "    # Text characteristics\n",
    "    print(f\"   üìù Text Characteristics:\")\n",
    "    print(f\"      ‚Ä¢ Average statement length: {df['text_length'].mean():.0f} characters\")\n",
    "    \n",
    "    print(f\"\\nüíæ FILES GENERATED TODAY:\")\n",
    "    files_generated = [\n",
    "        \"results/plots/day2_political_bias_analysis.png\",\n",
    "        \"results/plots/day2_advanced_text_visualizations.png\",\n",
    "        \"results/reports/dashboard_data.json\",\n",
    "        \"data/processed/liar_dataset_processed.csv\"\n",
    "    ]\n",
    "    \n",
    "    for file in files_generated:\n",
    "        print(f\"   üìÑ {file}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ PREPARATION FOR DAY 3:\")\n",
    "    print(\"   üìã Data profiling reports ready\")\n",
    "    print(\"   üìä Advanced visualizations completed\")\n",
    "    print(\"   üéõÔ∏è Dashboard data prepared\")\n",
    "    print(\"   üìà Statistical analysis comprehensive\")\n",
    "    print(\"   üèõÔ∏è Bias analysis thorough\")\n",
    "    \n",
    "    print(f\"\\n‚è∞ DAY 2 TIMELINE COMPLETED:\")\n",
    "    print(\"   ‚úÖ 9:00-11:00 AM: Advanced EDA & Linguistic Analysis\")\n",
    "    print(\"   ‚úÖ 11:00-1:00 PM: Statistical Testing & Correlation Analysis\")\n",
    "    print(\"   ‚úÖ 2:00-4:00 PM: Political Bias & Advanced Visualizations\")\n",
    "    \n",
    "    return {\n",
    "        'completion_status': 'Day 2 Complete',\n",
    "        'insights_generated': 4,\n",
    "        'files_generated': len(files_generated),\n",
    "        'next_phase': 'Day 3: Final Documentation & Reporting'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6939f14-c76e-4fa1-940e-febd8dc20a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
