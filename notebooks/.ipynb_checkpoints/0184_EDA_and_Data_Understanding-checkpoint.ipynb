{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a60956-5c1e-4054-a8df-051ce61ad59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de4d370-95f9-4215-b180-033119c6400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAKE NEWS DETECTION PROJECT ===\n",
      "Member: ITBIN-2211-0184\n",
      "Role: EDA & Documentation\n",
      "Environment Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== FAKE NEWS DETECTION PROJECT ===\")\n",
    "print(\"Member: ITBIN-2211-0184\")\n",
    "print(\"Role: EDA & Documentation\")\n",
    "print(\"Environment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da5a1ef-834c-4ae0-aa8c-a76ce27422aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. DATA LOADING AND INITIAL EXPLORATION\n",
    "\n",
    "def load_liar_dataset():\n",
    "    \"\"\"Load all three splits of the LIAR dataset\"\"\"\n",
    "    try:\n",
    "        # Column names for LIAR dataset\n",
    "        columns = [\n",
    "            'label', 'statement', 'subject', 'speaker', 'speaker_job',\n",
    "            'state_info', 'party_affiliation', 'barely_true_counts',\n",
    "            'false_counts', 'half_true_counts', 'mostly_true_counts',\n",
    "            'pants_fire_counts', 'context'\n",
    "        ]\n",
    "        \n",
    "        # Load datasets\n",
    "        train_df = pd.read_csv('data/raw/train.tsv', sep='\\t', names=columns, header=None)\n",
    "        test_df = pd.read_csv('data/raw/test.tsv', sep='\\t', names=columns, header=None)\n",
    "        valid_df = pd.read_csv('data/raw/valid.tsv', sep='\\t', names=columns, header=None)\n",
    "        \n",
    "        # Add dataset split information\n",
    "        train_df['split'] = 'train'\n",
    "        test_df['split'] = 'test'\n",
    "        valid_df['split'] = 'valid'\n",
    "        \n",
    "        # Combine all splits for comprehensive analysis\n",
    "        full_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        print(\"✅ Dataset loaded successfully!\")\n",
    "        print(f\"📊 Training samples: {len(train_df)}\")\n",
    "        print(f\"📊 Testing samples: {len(test_df)}\")\n",
    "        print(f\"📊 Validation samples: {len(valid_df)}\")\n",
    "        print(f\"📊 Total samples: {len(full_df)}\")\n",
    "        \n",
    "        return train_df, test_df, valid_df, full_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Dataset files not found!\")\n",
    "        print(\"Please ensure the following files are in data/raw/:\")\n",
    "        print(\"- train.tsv\")\n",
    "        print(\"- test.tsv\") \n",
    "        print(\"- valid.tsv\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a830c0-084e-452d-9c00-4a0256d1a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Dataset files not found!\n",
      "Please ensure the following files are in data/raw/:\n",
      "- train.tsv\n",
      "- test.tsv\n",
      "- valid.tsv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_df, test_df, valid_df, full_df = load_liar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75930438-71b0-4c8e-aeb2-3b9852b652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. BASIC DATA EXPLORATION\n",
    "\n",
    "def basic_data_exploration(df):\n",
    "    \"\"\"Perform basic exploration of the dataset\"\"\"\n",
    "    print(\"\\n=== BASIC DATA EXPLORATION ===\")\n",
    "    \n",
    "    # Dataset shape\n",
    "    print(f\"📋 Dataset Shape: {df.shape}\")\n",
    "    print(f\"📋 Features: {df.shape[1]}\")\n",
    "    print(f\"📋 Samples: {df.shape[0]}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\n📊 Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Missing values\n",
    "    print(\"\\n🔍 Missing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    # Label distribution\n",
    "    print(\"\\n🎯 Label Distribution:\")\n",
    "    label_counts = df['label'].value_counts()\n",
    "    label_pct = df['label'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    for label in label_counts.index:\n",
    "        print(f\"{label}: {label_counts[label]} ({label_pct[label]:.1f}%)\")\n",
    "    \n",
    "    return missing_df, label_counts\n",
    "\n",
    "# Perform basic exploration\n",
    "if full_df is not None:\n",
    "    missing_info, label_dist = basic_data_exploration(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6481c3f-5619-4a2d-8f44-1e9c1d353466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. COMPREHENSIVE VISUALIZATIONS\n",
    "\n",
    "def create_comprehensive_visualizations(df):\n",
    "    \"\"\"Create comprehensive EDA visualizations\"\"\"\n",
    "    print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    fig = plt.figure(figsize=(20, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bea9385-d281-4348-a2a3-dd8cb4c54447",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll columns in DataFrame:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdf\u001b[49m.columns.tolist())\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst 5 rows:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Print data inspection info\n",
    "    print(\"All columns in DataFrame:\", df.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Find potential label columns\n",
    "    possible_labels = [col for col in df.columns \n",
    "                      if 'label' in col.lower() \n",
    "                      or 'class' in col.lower() \n",
    "                      or 'category' in col.lower()\n",
    "                      or 'target' in col.lower()]\n",
    "    \n",
    "    print(\"\\nPossible label columns:\", possible_labels)\n",
    "    \n",
    "    if not possible_labels:\n",
    "        raise ValueError(\"No obvious label column found in the DataFrame\")\n",
    "    \n",
    "    # Use the first found label column\n",
    "    label_column = possible_labels[0]\n",
    "    \n",
    "    # 1. Label Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(4, 3, 1)\n",
    "    label_counts = df[label_column].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "    bars = plt.bar(label_counts.index, label_counts.values, color=colors)\n",
    "    plt.title(f'{label_column} Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Add value Labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 50,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: DataFrame 'df' is not defined. Please load your data first.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fab69b-eb00-46dd-9c8e-51a166757f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72db2e-2e5c-4672-ad57-a5402e448ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "new_columns = {\n",
    "    '2635.json': 'id',\n",
    "    'false': 'label',\n",
    "    'Says the Annies List political group supports third-trimester abortions on demand.': 'claim',\n",
    "    'abortion': 'topic',\n",
    "    'dwayne-bohac': 'person',\n",
    "    'State representative': 'position',\n",
    "    'Texas': 'state',\n",
    "    'republican': 'party',\n",
    "    '@': 'source_1',\n",
    "    '@.1': 'source_2',\n",
    "    '@.2': 'source_3',\n",
    "    '@.3': 'source_4',\n",
    "    'a mailer': 'source_5'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=new_columns)\n",
    "print(df.columns)  # Verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb2ea5-0ab6-41d7-9db2-b296eb7d3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot for 'label' column\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.title(\"Distribution of True/Fake Claims\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66acac-087b-4ec3-b2a5-6187b34bb506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by topic and label\n",
    "topic_counts = df.groupby(['topic', 'label']).size().unstack()\n",
    "topic_counts.plot(kind='bar', stacked=True)\n",
    "plt.title(\"Claims by Topic and Veracity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea70e2-92fa-4cc2-b3ef-49fc8822161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[['id', 'label', 'claim', 'topic', 'person']]\n",
    "sns.barplot(data=clean_df, x='topic', y='label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591214af-c5b7-469d-93ee-23f4f387a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = {\n",
    "    'false': 'label',  # Assuming 'false' is the original column name for labels\n",
    "}\n",
    "df = df.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998b030-1f73-4506-900f-a23b781ed3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot label distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=\"label\", data=df, palette=\"Set2\")\n",
    "\n",
    "plt.title(\"Label Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df62003-3d00-40c2-a665-ceefba9ee0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().to_csv(\"../results/0184_day1_stats_summary.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fafa0-5bd7-4268-9497-0da453f30374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
