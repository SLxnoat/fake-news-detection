{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662183c9-cb3d-40b9-ac08-9a57d435716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src/models')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37bde48-b27b-40c3-a19e-f4174cac5a54",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (hybrid_model_0173.py, line 455)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mC:\\LOcal D\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom src.models.hybrid_model_0173 import HybridFakeNewsDetector, HybridTrainer, evaluate_model, ModelExplainer\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m~\\fake-news-detection\\src\\models\\hybrid_model_0173.py:455\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif name == 'with_attention':\u001b[39m\n                                ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path(\"..\").resolve()  # Go up from notebooks to project root\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import with corrected class names\n",
    "from src.models.bert_extractor_0173 import BERTFeatureExtractor as EnhancedBERTExtractor, LIARDataset\n",
    "from src.models.hybrid_model_0173 import HybridFakeNewsDetector, HybridTrainer, evaluate_model, ModelExplainer\n",
    "\n",
    "print(\"ðŸš€ Day 2: Hybrid Architecture Development\")\n",
    "print(\"Member: 0173 - BERT Integration & Hybrid Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create alias for dataset loading function\n",
    "def load_liar_dataset(data_path=\"../data/raw\"):\n",
    "    dataset = LIARDataset(data_path)\n",
    "    success = dataset.load_data()\n",
    "    if success:\n",
    "        return dataset.train_df, dataset.valid_df, dataset.test_df\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Could not load LIAR dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e54ae-767f-4be6-8084-e59b0bb0ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment Check and Setup\n",
    "print(\"=== ENVIRONMENT CHECK ===\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
