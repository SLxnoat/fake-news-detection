{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f5a38e-8df5-4709-8276-62f935959262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import requests\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524d9db1-b998-43ec-87a0-62430b89dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282c1282-7e9f-4e01-9b43-55ca3f9f002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeMonitor:\n",
    "    def __init__(self, api_base_url=\"http://localhost:5000/api\"):\n",
    "        self.api_base_url = api_base_url\n",
    "        self.prediction_history = []\n",
    "        self.performance_metrics = {}\n",
    "        self.system_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3669da-44c5-4688-84c8-56b434800ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fetch_system_stats(self):\n",
    "        \"\"\"Fetch current system statistics\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_base_url}/stats\")\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3392de3b-5beb-4363-9cef-2c0581be4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def simulate_real_time_data(self, n_points=50):\n",
    "        \"\"\"Simulate real-time prediction data\"\"\"\n",
    "        timestamps = []\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        processing_times = []\n",
    "        \n",
    "        base_time = datetime.now() - timedelta(hours=2)\n",
    "        \n",
    "        for i in range(n_points):\n",
    "            timestamp = base_time + timedelta(minutes=i*2)\n",
    "            pred = np.random.choice(['real', 'fake'], p=[0.65, 0.35])\n",
    "            conf = np.random.normal(0.82, 0.12)\n",
    "            conf = max(0.5, min(0.99, conf))  # Clip to reasonable range\n",
    "            proc_time = np.random.exponential(0.25)\n",
    "            \n",
    "            timestamps.append(timestamp)\n",
    "            predictions.append(pred)\n",
    "            confidences.append(conf)\n",
    "            processing_times.append(proc_time)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'prediction': predictions,\n",
    "            'confidence': confidences,\n",
    "            'processing_time': processing_times\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb5f795-807f-4cd3-a033-2f20624a0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_real_time_dashboard(self, df):\n",
    "        \"\"\"Create comprehensive real-time monitoring dashboard\"\"\"\n",
    "        # Create subplots with CORRECTED specs\n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=2,\n",
    "            subplot_titles=[\n",
    "                'Predictions Over Time', 'Confidence Distribution',\n",
    "                'Processing Time Trends', 'Predictions by Hour',\n",
    "                'System Throughput', 'Alert Status'\n",
    "            ],\n",
    "            specs=[\n",
    "                [{\"type\": \"xy\", \"secondary_y\": True}, {\"type\": \"histogram\"}],\n",
    "                [{\"type\": \"xy\"}, {\"type\": \"bar\"}],\n",
    "                [{\"type\": \"indicator\"}, {\"type\": \"indicator\"}]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 1. Predictions over time with confidence\n",
    "        df_hourly = df.set_index('timestamp').resample('30T').agg({\n",
    "            'prediction': 'count',\n",
    "            'confidence': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_hourly['timestamp'], \n",
    "                y=df_hourly['prediction'],\n",
    "                mode='lines+markers', \n",
    "                name='Predictions/30min',\n",
    "                line=dict(color='blue')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_hourly['timestamp'], \n",
    "                y=df_hourly['confidence'],\n",
    "                mode='lines+markers', \n",
    "                name='Avg Confidence',\n",
    "                line=dict(color='red')\n",
    "            ),\n",
    "            row=1, col=1, secondary_y=True\n",
    "        )\n",
    "        \n",
    "        # 2. Confidence distribution\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=df['confidence'], \n",
    "                nbinsx=20, \n",
    "                name='Confidence Dist',\n",
    "                marker_color='lightblue'\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. Processing time trends\n",
    "        df_proc_time = df.set_index('timestamp').resample('30T')['processing_time'].mean().reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_proc_time['timestamp'], \n",
    "                y=df_proc_time['processing_time'],\n",
    "                mode='lines+markers', \n",
    "                name='Avg Processing Time',\n",
    "                line=dict(color='green')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Add processing time threshold line\n",
    "        fig.add_hline(\n",
    "            y=0.5, \n",
    "            line_dash=\"dash\", \n",
    "            line_color=\"red\", \n",
    "            annotation_text=\"SLA Threshold\", \n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # 4. Prediction count by hour\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        hourly_stats = df.groupby('hour').agg({\n",
    "            'prediction': 'count',\n",
    "            'confidence': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=hourly_stats['hour'], \n",
    "                y=hourly_stats['prediction'],\n",
    "                name='Predictions by Hour', \n",
    "                marker_color='orange'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # 5. System performance metrics - INDICATOR\n",
    "        current_throughput = len(df) / 2  # predictions per hour\n",
    "        avg_confidence = df['confidence'].mean()\n",
    "        avg_processing_time = df['processing_time'].mean()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"gauge+number\",\n",
    "                value=current_throughput,\n",
    "                domain={'x': [0, 1], 'y': [0, 1]},\n",
    "                title={'text': \"Throughput (pred/hr)\"},\n",
    "                gauge={\n",
    "                    'axis': {'range': [None, 100]},\n",
    "                    'bar': {'color': \"darkblue\"},\n",
    "                    'steps': [\n",
    "                        {'range': [0, 50], 'color': \"lightgray\"},\n",
    "                        {'range': [50, 80], 'color': \"yellow\"}\n",
    "                    ],\n",
    "                    'threshold': {\n",
    "                        'line': {'color': \"red\", 'width': 4},\n",
    "                        'thickness': 0.75, \n",
    "                        'value': 90\n",
    "                    }\n",
    "                }\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        \n",
    "        # 6. Alert status - INDICATOR\n",
    "        alerts = self.check_system_alerts(df)\n",
    "        alert_color = \"red\" if alerts['critical'] > 0 else \"yellow\" if alerts['warning'] > 0 else \"green\"\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"number+delta\",\n",
    "                value=alerts['total'],\n",
    "                title={'text': \"Active Alerts\"},\n",
    "                number={'font': {'color': alert_color}},\n",
    "                delta={'reference': 0, 'position': \"top\"}\n",
    "            ),\n",
    "            row=3, col=2\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            title_text=\"Real-Time Fake News Detection System Monitor\",\n",
    "            title_x=0.5,\n",
    "            showlegend=True,\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        \n",
    "        # Update axes labels\n",
    "        fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Confidence\", row=1, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text=\"Processing Time (s)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e059a738-c385-4cc8-aa6a-59c876f6c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def check_system_alerts(self, df):\n",
    "        \"\"\"Check for system alerts and anomalies\"\"\"\n",
    "        alerts = {'critical': 0, 'warning': 0, 'info': 0, 'total': 0}\n",
    "        \n",
    "        # Check processing time SLA\n",
    "        high_processing_time = df[df['processing_time'] > 0.5]\n",
    "        if len(high_processing_time) > len(df) * 0.1:  # More than 10%\n",
    "            alerts['critical'] += 1\n",
    "        \n",
    "        # Check confidence distribution\n",
    "        low_confidence = df[df['confidence'] < 0.6]\n",
    "        if len(low_confidence) > len(df) * 0.2:  # More than 20%\n",
    "            alerts['warning'] += 1\n",
    "        \n",
    "        # Check prediction rate anomalies\n",
    "        recent_hour = df[df['timestamp'] > (datetime.now() - timedelta(hours=1))]\n",
    "        if len(recent_hour) == 0:\n",
    "            alerts['critical'] += 1\n",
    "        elif len(recent_hour) < 5:  # Less than 5 predictions in last hour\n",
    "            alerts['warning'] += 1\n",
    "        \n",
    "        # Check for fake news spike\n",
    "        fake_rate = len(df[df['prediction'] == 'fake']) / len(df) if len(df) > 0 else 0\n",
    "        if fake_rate > 0.6:  # More than 60% fake\n",
    "            alerts['warning'] += 1\n",
    "        \n",
    "        alerts['total'] = alerts['critical'] + alerts['warning'] + alerts['info']\n",
    "        return alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f79abf-95b6-48d6-ae14-3bb22e4eedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generate_performance_report(self, df):\n",
    "        \"\"\"Generate detailed performance report\"\"\"\n",
    "        report = {'timestamp': datetime.now().isoformat(),'total_predictions': len(df),'time_period': f\"{df['timestamp'].min()} to {df['timestamp'].max()}\",'prediction_distribution': df['prediction'].value_counts().to_dict(),'avg_confidence': df['confidence'].mean(),'avg_processing_time': df['processing_time'].mean(),'max_processing_time': df['processing_time'].max(),'sla_compliance': len(df[df['processing_time'] <= 0.5]) / len(df) * 100,'confidence_quartiles': df['confidence'].quantile([0.25, 0.5, 0.75]).to_dict(),'hourly_distribution': df['timestamp'].dt.hour.value_counts().sort_index().to_dict()}\n",
    "        \n",
    "        return report\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c836e9b-b8c4-4513-bb83-65656a2c054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample real-time monitoring data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RealTimeMonitor' object has no attribute 'simulate_real_time_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Generate sample real-time data\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating sample real-time monitoring data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m df = \u001b[43mmonitor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulate_real_time_data\u001b[49m(n_points=\u001b[32m200\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Display basic statistics\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== System Overview ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RealTimeMonitor' object has no attribute 'simulate_real_time_data'"
     ]
    }
   ],
   "source": [
    "def export_monitoring_data(self, df, filename=None):\n",
    "        \"\"\"Export monitoring data for further analysis\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"monitoring_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        \n",
    "        # Add derived metrics\n",
    "        export_df = df.copy()\n",
    "        export_df['hour'] = export_df['timestamp'].dt.hour\n",
    "        export_df['minute'] = export_df['timestamp'].dt.minute\n",
    "        export_df['day_of_week'] = export_df['timestamp'].dt.day_name()\n",
    "        export_df['is_fake'] = (export_df['prediction'] == 'fake').astype(int)\n",
    "        export_df['high_confidence'] = (export_df['confidence'] > 0.8).astype(int)\n",
    "        export_df['slow_processing'] = (export_df['processing_time'] > 0.5).astype(int)\n",
    "        \n",
    "        export_df.to_csv(filename, index=False)\n",
    "        print(f\"Monitoring data exported to {filename}\")\n",
    "        \n",
    "        return filename\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = RealTimeMonitor()\n",
    "\n",
    "# Generate sample real-time data\n",
    "print(\"Generating sample real-time monitoring data...\")\n",
    "df = monitor.simulate_real_time_data(n_points=200)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n=== System Overview ===\")\n",
    "print(f\"Total Predictions: {len(df)}\")\n",
    "print(f\"Time Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Fake News Rate: {len(df[df['prediction'] == 'fake']) / len(df) * 100:.1f}%\")\n",
    "print(f\"Average Confidence: {df['confidence'].mean():.3f}\")\n",
    "print(f\"Average Processing Time: {df['processing_time'].mean():.3f}s\")\n",
    "\n",
    "# Check alerts\n",
    "alerts = monitor.check_system_alerts(df)\n",
    "print(f\"\\n=== Alert Status ===\")\n",
    "print(f\"Critical Alerts: {alerts['critical']}\")\n",
    "print(f\"Warning Alerts: {alerts['warning']}\")\n",
    "print(f\"Total Active Alerts: {alerts['total']}\")\n",
    "\n",
    "# Create and display dashboard\n",
    "print(\"\\n=== Real-Time Dashboard ===\")\n",
    "dashboard = monitor.create_real_time_dashboard(df)\n",
    "dashboard.show()\n",
    "\n",
    "# Generate performance report\n",
    "report = monitor.generate_performance_report(df)\n",
    "print(\"\\n=== Performance Report ===\")\n",
    "print(json.dumps(report, indent=2, default=str))\n",
    "\n",
    "# Export data\n",
    "export_file = monitor.export_monitoring_data(df)\n",
    "print(f\"\\nData exported to: {export_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e17e4c-d4fc-41b5-85e3-def97cdf71b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
