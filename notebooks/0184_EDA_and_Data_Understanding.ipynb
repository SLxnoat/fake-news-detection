{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a60956-5c1e-4054-a8df-051ce61ad59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de4d370-95f9-4215-b180-033119c6400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAKE NEWS DETECTION PROJECT ===\n",
      "Member: ITBIN-2211-0184\n",
      "Role: EDA & Documentation\n",
      "Environment Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== FAKE NEWS DETECTION PROJECT ===\")\n",
    "print(\"Member: ITBIN-2211-0184\")\n",
    "print(\"Role: EDA & Documentation\")\n",
    "print(\"Environment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da5a1ef-834c-4ae0-aa8c-a76ce27422aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. DATA LOADING AND INITIAL EXPLORATION\n",
    "\n",
    "def load_liar_dataset():\n",
    "    \"\"\"Load all three splits of the LIAR dataset\"\"\"\n",
    "    try:\n",
    "        # Column names for LIAR dataset\n",
    "        columns = [\n",
    "            'label', 'statement', 'subject', 'speaker', 'speaker_job',\n",
    "            'state_info', 'party_affiliation', 'barely_true_counts',\n",
    "            'false_counts', 'half_true_counts', 'mostly_true_counts',\n",
    "            'pants_fire_counts', 'context'\n",
    "        ]\n",
    "        \n",
    "        # Load datasets\n",
    "        train_df = pd.read_csv('data/raw/train.tsv', sep='\\t', names=columns, header=None)\n",
    "        test_df = pd.read_csv('data/raw/test.tsv', sep='\\t', names=columns, header=None)\n",
    "        valid_df = pd.read_csv('data/raw/valid.tsv', sep='\\t', names=columns, header=None)\n",
    "        \n",
    "        # Add dataset split information\n",
    "        train_df['split'] = 'train'\n",
    "        test_df['split'] = 'test'\n",
    "        valid_df['split'] = 'valid'\n",
    "        \n",
    "        # Combine all splits for comprehensive analysis\n",
    "        full_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        print(\"âœ… Dataset loaded successfully!\")\n",
    "        print(f\"ðŸ“Š Training samples: {len(train_df)}\")\n",
    "        print(f\"ðŸ“Š Testing samples: {len(test_df)}\")\n",
    "        print(f\"ðŸ“Š Validation samples: {len(valid_df)}\")\n",
    "        print(f\"ðŸ“Š Total samples: {len(full_df)}\")\n",
    "        \n",
    "        return train_df, test_df, valid_df, full_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Dataset files not found!\")\n",
    "        print(\"Please ensure the following files are in data/raw/:\")\n",
    "        print(\"- train.tsv\")\n",
    "        print(\"- test.tsv\") \n",
    "        print(\"- valid.tsv\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a830c0-084e-452d-9c00-4a0256d1a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Dataset files not found!\n",
      "Please ensure the following files are in data/raw/:\n",
      "- train.tsv\n",
      "- test.tsv\n",
      "- valid.tsv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_df, test_df, valid_df, full_df = load_liar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75930438-71b0-4c8e-aeb2-3b9852b652d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. BASIC DATA EXPLORATION\n",
    "\n",
    "def basic_data_exploration(df):\n",
    "    \"\"\"Perform basic exploration of the dataset\"\"\"\n",
    "    print(\"\\n=== BASIC DATA EXPLORATION ===\")\n",
    "    \n",
    "    # Dataset shape\n",
    "    print(f\"ðŸ“‹ Dataset Shape: {df.shape}\")\n",
    "    print(f\"ðŸ“‹ Features: {df.shape[1]}\")\n",
    "    print(f\"ðŸ“‹ Samples: {df.shape[0]}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\nðŸ“Š Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Missing values\n",
    "    print(\"\\nðŸ” Missing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    # Label distribution\n",
    "    print(\"\\nðŸŽ¯ Label Distribution:\")\n",
    "    label_counts = df['label'].value_counts()\n",
    "    label_pct = df['label'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    for label in label_counts.index:\n",
    "        print(f\"{label}: {label_counts[label]} ({label_pct[label]:.1f}%)\")\n",
    "    \n",
    "    return missing_df, label_counts\n",
    "\n",
    "# Perform basic exploration\n",
    "if full_df is not None:\n",
    "    missing_info, label_dist = basic_data_exploration(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6481c3f-5619-4a2d-8f44-1e9c1d353466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(df):\n",
    "    \"\"\"Create comprehensive EDA visualizations\"\"\"\n",
    "    print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    \n",
    "    # 1. Label Distribution\n",
    "    plt.subplot(4, 3, 1)\n",
    "    label_counts = df['label'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "    bars = plt.bar(label_counts.index, label_counts.values, color=colors)\n",
    "    plt.title('Label Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 50,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Text Length Distribution\n",
    "    plt.subplot(4, 3, 2)\n",
    "    plt.hist(df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Statement Length Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Text Length (characters)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(df['text_length'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"text_length\"].mean():.0f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Word Count by Label\n",
    "    plt.subplot(4, 3, 3)\n",
    "    sns.boxplot(data=df, x='label', y='word_count')\n",
    "    plt.title('Word Count by Label', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Word Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 4. Party Affiliation Distribution\n",
    "    plt.subplot(4, 3, 4)\n",
    "    party_counts = df['party_affiliation'].value_counts().head(10)\n",
    "    plt.barh(range(len(party_counts)), party_counts.values)\n",
    "    plt.yticks(range(len(party_counts)), party_counts.index)\n",
    "    plt.title('Top 10 Party Affiliations', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    # 5. Subject Distribution\n",
    "    plt.subplot(4, 3, 5)\n",
    "    subject_counts = df['subject'].value_counts().head(10)\n",
    "    plt.barh(range(len(subject_counts)), subject_counts.values, color='lightcoral')\n",
    "    plt.yticks(range(len(subject_counts)), subject_counts.index)\n",
    "    plt.title('Top 10 Subjects', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    # 6. Credibility Score Distribution\n",
    "    plt.subplot(4, 3, 6)\n",
    "    plt.hist(df['credibility_score'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    plt.title('Speaker Credibility Score Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Credibility Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(df['credibility_score'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {df[\"credibility_score\"].mean():.3f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 7. Label vs Credibility Score\n",
    "    plt.subplot(4, 3, 7)\n",
    "    sns.boxplot(data=df, x='label', y='credibility_score')\n",
    "    plt.title('Credibility Score by Label', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Credibility Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 8. Truth Score vs Text Length\n",
    "    plt.subplot(4, 3, 8)\n",
    "    plt.scatter(df['text_length'], df['truth_score'], alpha=0.5, color='purple')\n",
    "    plt.title('Truth Score vs Text Length', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Truth Score')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df['text_length'].dropna(), df['truth_score'].dropna(), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df['text_length'], p(df['text_length']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # 9. Correlation Heatmap\n",
    "    plt.subplot(4, 3, 9)\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = ['text_length', 'word_count', 'sentence_count', 'credibility_score', \n",
    "                   'truth_score', 'total_statements']\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 10. Statement Count by Split\n",
    "    plt.subplot(4, 3, 10)\n",
    "    split_counts = df['split'].value_counts()\n",
    "    plt.pie(split_counts.values, labels=split_counts.index, autopct='%1.1f%%',\n",
    "            colors=['lightblue', 'lightgreen', 'lightyellow'])\n",
    "    plt.title('Data Split Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 11. Top Speakers by Statement Count\n",
    "    plt.subplot(4, 3, 11)\n",
    "    top_speakers = df['speaker'].value_counts().head(10)\n",
    "    plt.barh(range(len(top_speakers)), top_speakers.values, color='orange')\n",
    "    plt.yticks(range(len(top_speakers)), top_speakers.index)\n",
    "    plt.title('Top 10 Speakers by Statement Count', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Number of Statements')\n",
    "    \n",
    "    # 12. Average Truth Score by Party\n",
    "    plt.subplot(4, 3, 12)\n",
    "    party_truth = df.groupby('party_affiliation')['truth_score'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.barh(range(len(party_truth)), party_truth.values, color='mediumpurple')\n",
    "    plt.yticks(range(len(party_truth)), party_truth.index)\n",
    "    plt.title('Average Truth Score by Party (Top 10)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Average Truth Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/comprehensive_eda.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"ðŸ“Š Comprehensive EDA visualization saved to 'results/plots/comprehensive_eda.png'\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bea9385-d281-4348-a2a3-dd8cb4c54447",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. COMPREHENSIVE VISUALIZATIONS\n",
    "\n",
    "def create_comprehensive_visualizations(df):\n",
    "    \"\"\"Create comprehensive EDA visualizations\"\"\"\n",
    "    print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    fig = plt.figure(figsize=(20, 24))\n",
    "    \n",
    "    # 1. Label Distribution\n",
    "    plt.subplot(4, 3, 1)\n",
    "    label_counts = df['label'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(label_counts)))\n",
    "    bars = plt.bar(label_counts.index, label_counts.values, color=colors)\n",
    "    plt.title('Label Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 50,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Text Length Distribution\n",
    "    plt.subplot(4, 3, 2)\n",
    "    plt.hist(df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Statement Length Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Text Length (characters)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(df['text_length'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"text_length\"].mean():.0f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Word Count by Label\n",
    "    plt.subplot(4, 3, 3)\n",
    "    sns.boxplot(data=df, x='label', y='word_count')\n",
    "    plt.title('Word Count by Label', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Word Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 4. Party Affiliation Distribution\n",
    "    plt.subplot(4, 3, 4)\n",
    "    party_counts = df['party_affiliation'].value_counts().head(10)\n",
    "    plt.barh(range(len(party_counts)), party_counts.values)\n",
    "    plt.yticks(range(len(party_counts)), party_counts.index)\n",
    "    plt.title('Top 10 Party Affiliations', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    # 5. Subject Distribution\n",
    "    plt.subplot(4, 3, 5)\n",
    "    subject_counts = df['subject'].value_counts().head(10)\n",
    "    plt.barh(range(len(subject_counts)), subject_counts.values, color='lightcoral')\n",
    "    plt.yticks(range(len(subject_counts)), subject_counts.index)\n",
    "    plt.title('Top 10 Subjects', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    \n",
    "    # 6. Credibility Score Distribution\n",
    "    plt.subplot(4, 3, 6)\n",
    "    plt.hist(df['credibility_score'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    plt.title('Speaker Credibility Score Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Credibility Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(df['credibility_score'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {df[\"credibility_score\"].mean():.3f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 7. Label vs Credibility Score\n",
    "    plt.subplot(4, 3, 7)\n",
    "    sns.boxplot(data=df, x='label', y='credibility_score')\n",
    "    plt.title('Credibility Score by Label', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Truth Labels')\n",
    "    plt.ylabel('Credibility Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 8. Truth Score vs Text Length\n",
    "    plt.subplot(4, 3, 8)\n",
    "    plt.scatter(df['text_length'], df['truth_score'], alpha=0.5, color='purple')\n",
    "    plt.title('Truth Score vs Text Length', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Truth Score')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df['text_length'].dropna(), df['truth_score'].dropna(), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df['text_length'], p(df['text_length']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # 9. Correlation Heatmap\n",
    "    plt.subplot(4, 3, 9)\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = ['text_length', 'word_count', 'sentence_count', 'credibility_score', \n",
    "                   'truth_score', 'total_statements']\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 10. Statement Count by Split\n",
    "    plt.subplot(4, 3, 10)\n",
    "    split_counts = df['split'].value_counts()\n",
    "    plt.pie(split_counts.values, labels=split_counts.index, autopct='%1.1f%%',\n",
    "            colors=['lightblue', 'lightgreen', 'lightyellow'])\n",
    "    plt.title('Data Split Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 11. Top Speakers by Statement Count\n",
    "    plt.subplot(4, 3, 11)\n",
    "    top_speakers = df['speaker'].value_counts().head(10)\n",
    "    plt.barh(range(len(top_speakers)), top_speakers.values, color='orange')\n",
    "    plt.yticks(range(len(top_speakers)), top_speakers.index)\n",
    "    plt.title('Top 10 Speakers by Statement Count', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Number of Statements')\n",
    "    \n",
    "    # 12. Average Truth Score by Party\n",
    "    plt.subplot(4, 3, 12)\n",
    "    party_truth = df.groupby('party_affiliation')['truth_score'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.barh(range(len(party_truth)), party_truth.values, color='mediumpurple')\n",
    "    plt.yticks(range(len(party_truth)), party_truth.index)\n",
    "    plt.title('Average Truth Score by Party (Top 10)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Average Truth Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/comprehensive_eda.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"ðŸ“Š Comprehensive EDA visualization saved to 'results/plots/comprehensive_eda.png'\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create visualizations\n",
    "if full_df is not None:\n",
    "    viz_fig = create_comprehensive_visualizations(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4ae105-3161-4621-b341-2364743acef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. ADVANCED ANALYSIS\n",
    "\n",
    "def advanced_analysis(df):\n",
    "    \"\"\"Perform advanced statistical analysis\"\"\"\n",
    "    print(\"\\n=== ADVANCED ANALYSIS ===\")\n",
    "    \n",
    "    # Chi-square test for categorical associations\n",
    "    from scipy.stats import chi2_contingency\n",
    "    \n",
    "    # Test association between party and label\n",
    "    party_label_crosstab = pd.crosstab(df['party_affiliation'], df['label'])\n",
    "    chi2, p_val, dof, expected = chi2_contingency(party_label_crosstab)\n",
    "    \n",
    "    print(f\"ðŸ§® Chi-square test (Party vs Label):\")\n",
    "    print(f\"   Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"   P-value: {p_val:.4e}\")\n",
    "    print(f\"   Degrees of freedom: {dof}\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    print(f\"\\nðŸ“Š Key Correlations:\")\n",
    "    correlations = df[['text_length', 'credibility_score', 'truth_score', 'total_statements']].corr()\n",
    "    print(f\"   Text Length vs Truth Score: {correlations.loc['text_length', 'truth_score']:.4f}\")\n",
    "    print(f\"   Credibility vs Truth Score: {correlations.loc['credibility_score', 'truth_score']:.4f}\")\n",
    "    \n",
    "    # Group analysis by subject\n",
    "    subject_analysis = df.groupby('subject').agg({\n",
    "        'truth_score': ['mean', 'std', 'count'],\n",
    "        'text_length': 'mean',\n",
    "        'credibility_score': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Subject Analysis (Top 5 by count):\")\n",
    "    top_subjects = df['subject'].value_counts().head().index\n",
    "    print(subject_analysis.loc[top_subjects])\n",
    "    \n",
    "    return party_label_crosstab, subject_analysis\n",
    "\n",
    "# Perform advanced analysis\n",
    "if full_df is not None:\n",
    "    crosstab_result, subject_stats = advanced_analysis(full_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6ad193d-7f09-48a8-9823-3d91d2b5ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. DATA QUALITY ASSESSMENT\n",
    "\n",
    "def data_quality_assessment(df):\n",
    "    \"\"\"Assess data quality and create report\"\"\"\n",
    "    print(\"\\n=== DATA QUALITY ASSESSMENT ===\")\n",
    "    \n",
    "    quality_report = {}\n",
    "    \n",
    "    # Completeness\n",
    "    completeness = (df.count() / len(df)) * 100\n",
    "    quality_report['completeness'] = completeness\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    quality_report['total_duplicates'] = duplicates\n",
    "    quality_report['duplicate_percentage'] = (duplicates / len(df)) * 100\n",
    "    \n",
    "    # Unique values\n",
    "    unique_counts = df.nunique()\n",
    "    quality_report['unique_counts'] = unique_counts\n",
    "    \n",
    "    # Text quality checks\n",
    "    empty_statements = df['statement'].isna().sum()\n",
    "    very_short_statements = (df['text_length'] < 10).sum()\n",
    "    very_long_statements = (df['text_length'] > 500).sum()\n",
    "    \n",
    "    print(f\"ðŸ“‹ Data Quality Report:\")\n",
    "    print(f\"   Total samples: {len(df)}\")\n",
    "    print(f\"   Complete records: {(df.dropna().shape[0] / len(df)) * 100:.1f}%\")\n",
    "    print(f\"   Duplicate records: {duplicates} ({quality_report['duplicate_percentage']:.1f}%)\")\n",
    "    print(f\"   Empty statements: {empty_statements}\")\n",
    "    print(f\"   Very short statements (<10 chars): {very_short_statements}\")\n",
    "    print(f\"   Very long statements (>500 chars): {very_long_statements}\")\n",
    "    \n",
    "    # Feature completeness\n",
    "    print(f\"\\nðŸ“Š Feature Completeness:\")\n",
    "    for col in df.columns:\n",
    "        if completeness[col] < 100:\n",
    "            print(f\"   {col}: {completeness[col]:.1f}% complete\")\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Assess data quality\n",
    "if full_df is not None:\n",
    "    quality_report = data_quality_assessment(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2258a3-944e-4934-b21c-962f17c9f540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
