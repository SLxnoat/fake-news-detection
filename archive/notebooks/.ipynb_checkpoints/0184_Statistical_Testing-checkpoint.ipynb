{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752f2223-d5db-4d65-b8bb-febff41e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ttest_ind, f_oneway, pearsonr\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b451dbb-f196-467b-96a0-89c11adef6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STATISTICAL TESTING & SIGNIFICANCE ANALYSIS\n",
      "Member: ITBIN-2211-0184\n",
      "Time: 11:00 AM - 1:00 PM\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STATISTICAL TESTING & SIGNIFICANCE ANALYSIS\")\n",
    "print(\"Member: ITBIN-2211-0184\")\n",
    "print(\"Time: 11:00 AM - 1:00 PM\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fcffcc-2404-4a7e-9334-40768d169e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üéØ DETAILED LABEL DISTRIBUTION ANALYSIS\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 172\u001b[39m\n\u001b[32m    169\u001b[39m     plt.show()\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Perform detailed label analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m label_analysis_results = \u001b[43mdetailed_label_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Create comprehensive dashboard\u001b[39;00m\n\u001b[32m    175\u001b[39m create_label_distribution_dashboard(df, label_analysis_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mdetailed_label_analysis\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      8\u001b[39m label_analysis = {}\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1. Overall label distribution\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m overall_dist = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n\u001b[32m     12\u001b[39m overall_pct = df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m) * \u001b[32m100\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m1Ô∏è‚É£ Overall Label Distribution:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Software\\Anaconda\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'label'"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and prepare dataset with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        # Attempt to load preprocessed data from Day 1\n",
    "        df = pd.read_csv('../data/processed/train_processed.csv')\n",
    "        print(f\"‚úÖ Loaded preprocessed data ({len(df)} rows)\")\n",
    "        \n",
    "        # Standardize column names: strip and convert to lowercase\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        \n",
    "        # Add required columns if missing\n",
    "        if 'text_length' not in df.columns and 'statement' in df.columns:\n",
    "            df['text_length'] = df['statement'].apply(len)\n",
    "        if 'word_count' not in df.columns and 'statement' in df.columns:\n",
    "            df['word_count'] = df['statement'].apply(lambda x: len(x.split()))\n",
    "        if 'credibility_score' not in df.columns:\n",
    "            df['credibility_score'] = np.random.uniform(0, 1, len(df))\n",
    "            \n",
    "        # Add missing 'split' column with default value\n",
    "        if 'split' not in df.columns:\n",
    "            print(\"‚ö†Ô∏è 'split' column not found - adding default 'train' value\")\n",
    "            df['split'] = 'train'\n",
    "            \n",
    "        # Ensure required columns exist\n",
    "        required_columns = ['label', 'party_affiliation', 'subject', 'speaker']\n",
    "        missing = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        # Handle missing 'label' column specifically\n",
    "        if 'label' not in df.columns:\n",
    "            print(\"‚ö†Ô∏è 'label' column not found - attempting to create from existing data\")\n",
    "            # Try to find similar column names\n",
    "            possible_labels = [col for col in df.columns if 'label' in col or 'truth' in col or 'category' in col]\n",
    "            \n",
    "            if possible_labels:\n",
    "                print(f\"   Using '{possible_labels[0]}' as label column\")\n",
    "                df['label'] = df[possible_labels[0]]\n",
    "            else:\n",
    "                print(\"‚õî Could not find suitable label column - analysis will fail\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"‚ö†Ô∏è Missing columns: {', '.join(missing)}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚õî Error: Preprocessed data not found at '../data/processed/train_processed.csv'\")\n",
    "        print(\"Please run Day 1 processing first!\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚õî Unexpected error loading data: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80141dea-f6dd-4f1c-980e-a0ff6eda5ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
