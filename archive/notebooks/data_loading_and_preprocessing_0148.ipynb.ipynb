{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300aa8cc-091f-48e9-86d6-f571b36e0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4734b9-43d4-4f5a-a32f-26c40486be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root directory to Python path\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "root_dir = os.path.dirname(current_dir) if os.path.basename(current_dir) == \"notebooks\" else current_dir\n",
    "sys.path.append(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207501f8-60c8-4735-bca5-061e0e9792fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Module import error: No module named 'src.preprocessing.text_processor'\n",
      "Continuing with limited functionality\n"
     ]
    }
   ],
   "source": [
    "# Import custom modules after setting up paths\n",
    "try:\n",
    "    from src.preprocessing.text_processor import TextPreprocessor\n",
    "    from src.preprocessing.metadata_processor import MetadataProcessor\n",
    "    print(\"✓ Custom modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Module import error: {e}\")\n",
    "    print(\"Continuing with limited functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7963b42a-4ebb-4a09-b219-2c094e4fc523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Loading and Preprocessing Pipeline\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Starting Data Loading and Preprocessing Pipeline\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f45f5e-7b52-4aaf-80a6-1f1803e78811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_liar_dataset():\n",
    "    \"\"\"Load the LIAR dataset from TSV files with robust path handling.\"\"\"\n",
    "    try:\n",
    "        # Get current directory and adjust paths\n",
    "        current_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
    "        \n",
    "        # Navigate to correct data directory\n",
    "        if \"notebooks\" in current_dir:\n",
    "            data_dir = os.path.join(os.path.dirname(current_dir), \"data\", \"raw\")\n",
    "        else:\n",
    "            data_dir = os.path.join(current_dir, \"data\", \"raw\")\n",
    "            \n",
    "        print(f\"Loading data from: {data_dir}\")\n",
    "        \n",
    "        # Define file paths\n",
    "        train_file = os.path.join(data_dir, \"train.tsv\")\n",
    "        test_file = os.path.join(data_dir, \"test.tsv\")\n",
    "        valid_file = os.path.join(data_dir, \"valid.tsv\")\n",
    "        \n",
    "        # Column names for LIAR dataset\n",
    "        columns = [\n",
    "            'label', 'statement', 'subject', 'speaker', 'speaker_job', \n",
    "            'state_info', 'party_affiliation', 'barely_true_counts', \n",
    "            'false_counts', 'half_true_counts', 'mostly_true_counts', \n",
    "            'pants_fire_counts', 'context'\n",
    "        ]\n",
    "        \n",
    "        datasets = {}\n",
    "        \n",
    "        # Load training data\n",
    "        train_df = pd.read_csv(train_file, sep='\\t', header=None, names=columns)\n",
    "        datasets['train'] = train_df\n",
    "        print(f\"✓ Loaded training data: {train_df.shape}\")\n",
    "            \n",
    "        # Load test data\n",
    "        test_df = pd.read_csv(test_file, sep='\\t', header=None, names=columns)\n",
    "        datasets['test'] = test_df\n",
    "        print(f\"✓ Loaded test data: {test_df.shape}\")\n",
    "            \n",
    "        # Load validation data\n",
    "        valid_df = pd.read_csv(valid_file, sep='\\t', header=None, names=columns)\n",
    "        datasets['valid'] = valid_df\n",
    "        print(f\"✓ Loaded validation data: {valid_df.shape}\")\n",
    "            \n",
    "        return datasets\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        print(\"Creating sample data...\")\n",
    "        return create_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadd5bf7-15ae-44f8-9e01-149f369a373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample data with simplified structure\"\"\"\n",
    "    sample_data = pd.DataFrame({\n",
    "        'label': ['true', 'false', 'half-true'],\n",
    "        'statement': [\n",
    "            'The sky is blue',\n",
    "            'Water boils at 50 degrees Celsius',\n",
    "            'Humans have 5 senses'\n",
    "        ],\n",
    "        'subject': ['science', 'science', 'biology'],\n",
    "        'speaker': ['John Doe', 'Jane Smith', 'Alan Turing'],\n",
    "        'speaker_job': ['Scientist', 'Researcher', 'Mathematician'],\n",
    "        'state_info': ['CA', 'NY', 'UK'],\n",
    "        'party_affiliation': ['Independent', 'Democrat', 'Nonpartisan'],\n",
    "        'barely_true_counts': [1, 3, 2],\n",
    "        'false_counts': [0, 5, 1],\n",
    "        'half_true_counts': [2, 1, 4],\n",
    "        'mostly_true_counts': [4, 0, 3],\n",
    "        'pants_fire_counts': [0, 2, 0],\n",
    "        'context': ['Weather report', 'Science class', 'Biology lecture']\n",
    "    })\n",
    "    return {'train': sample_data, 'test': sample_data, 'valid': sample_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e3d983-21a7-4b4f-b539-9cc3b6aa2ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\mayur\\fake-news-detection\\data\\raw\n",
      "✓ Loaded training data: (10240, 13)\n",
      "✓ Loaded test data: (1267, 13)\n",
      "✓ Loaded validation data: (1284, 13)\n",
      "Loaded datasets: ['train', 'test', 'valid']\n",
      "\n",
      "============================================================\n",
      "INITIAL DATA EXPLORATION\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x550 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    datasets = load_liar_dataset()\n",
    "    print(f\"Loaded datasets: {list(datasets.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"Critical error: {e}\")\n",
    "    datasets = create_sample_data()\n",
    "\n",
    "# ==========================================\n",
    "# 2. INITIAL DATA EXPLORATION (SAFER)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INITIAL DATA EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'train' in datasets:\n",
    "    train_df = datasets['train']\n",
    "    \n",
    "    # ... (rest of your exploration code remains the same) ...\n",
    "    # Remember to create '../results/figures/' directory if it doesn't exist\n",
    "    os.makedirs('../results/figures/', exist_ok=True)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/initial_label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training data available in datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c802e92-7dfc-4875-9540-d63639771066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
